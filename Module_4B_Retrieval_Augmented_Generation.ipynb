{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8de8df73-a9fe-480a-acc6-9a6837bf48d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your LangSmith API key (optional):  ········\n",
      "Enter your Tavily API key (optional):  ········\n",
      "Enter your OpenAI API key:  ········\n"
     ]
    }
   ],
   "source": [
    "# --- Full Setup: LangSmith (optional), Tavily (optional), and OpenAI (required) ---\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "from langchain_openai import ChatOpenAI  # OpenAI chat model integration\n",
    "\n",
    "# Optional: Enable LangSmith tracing for debugging chains (press Enter to skip)\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key (optional): \")\n",
    "\n",
    "# Optional: Set Tavily API key for web search capabilities (press Enter to skip)\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key (optional): \")\n",
    "\n",
    "# Required: Set OpenAI API key to access models like GPT-4o\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# Initialize the OpenAI LLM you'll use for RAG\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")  # You can change this to \"gpt-3.5-turbo\" or \"gpt-4\" if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5b3d20f-9cf3-4a32-9946-07e2f47460aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize OpenAI's Embedding Model for text vectorization ---\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings  # Import OpenAI's embeddings class\n",
    "\n",
    "# Create an instance of the embedding model\n",
    "# This will convert text into vector representations for use in retrieval\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "848ee4d8-cf4c-4236-865a-a1b168f00b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create a simple in-memory vector store for storing and retrieving document vectors ---\n",
    "\n",
    "from langchain_core.vectorstores import InMemoryVectorStore  # Import in-memory store (no persistence)\n",
    "\n",
    "# Initialize the vector store using the embedding model\n",
    "# This is useful for small, temporary apps or testing purposes\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5c8ca20-52f0-4083-a7e7-71073ae5278b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition is the process of breaking a complicated task into smaller, manageable steps. It utilizes techniques like Chain of Thought (CoT) and Tree of Thoughts to enhance model performance by prompting the model to think step by step. This approach allows for more efficient problem-solving and provides insight into the model's reasoning process.\n"
     ]
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "import bs4  # Used by the WebBaseLoader to parse HTML content\n",
    "from langchain import hub  # For pulling shared prompt templates from LangChain Hub\n",
    "from langchain_community.document_loaders import WebBaseLoader  # Loads web pages as documents\n",
    "from langchain_core.documents import Document  # LangChain document format\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter  # Splits text into chunks\n",
    "from langgraph.graph import START, StateGraph  # Used to define and run a LangGraph\n",
    "from typing_extensions import List, TypedDict  # Type hinting for LangGraph state\n",
    "\n",
    "# --- Load and Chunk Website Content ---\n",
    "# Create a loader to pull the blog post content, filtering only the post-related HTML sections\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),  # Target blog URL\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")  # Only include relevant page sections\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()  # Load the blog post as a list of Document objects\n",
    "\n",
    "# Split the blog post into manageable text chunks for vector search\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# --- Index the Chunks ---\n",
    "# Embed and store all the chunks into your vector store (e.g., Chroma or InMemoryVectorStore)\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# --- Define Prompt for the Generator ---\n",
    "# Pull a reusable RAG prompt template from LangChain Hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# --- Define App State Structure ---\n",
    "# This defines the data that moves through the RAG chain: question in, context in, answer out\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "# --- Define Retrieval Step ---\n",
    "# Takes the user question and retrieves the most relevant document chunks from the vector store\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "# --- Define Generation Step ---\n",
    "# Uses the prompt and retrieved docs to generate an answer via the chat model\n",
    "def generate(state: State):\n",
    "    # Combine the retrieved chunks into one string for context\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    \n",
    "    # Fill in the prompt template with the question and the context\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    \n",
    "    # Generate the final answer using the LLM\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# --- Compile LangGraph ---\n",
    "# Set up the graph of your RAG workflow with defined steps\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "\n",
    "# Connect the starting point to the first step in the chain\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "\n",
    "# Compile the graph into an executable app\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# --- Run the RAG App with a Test Question ---\n",
    "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "\n",
    "# Print the generated answer\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bb689ca-990f-46fd-beac-5914c0573364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 43130\n"
     ]
    }
   ],
   "source": [
    "import bs4  # BeautifulSoup for parsing HTML\n",
    "from langchain_community.document_loaders import WebBaseLoader  # Loads webpages as LangChain Documents\n",
    "\n",
    "# --- Define which HTML content to keep ---\n",
    "# This tells BeautifulSoup to only keep specific parts of the page (by class name)\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "\n",
    "# --- Set up the web document loader ---\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),  # Target blog URL\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},  # Apply the strainer to filter out unnecessary HTML\n",
    ")\n",
    "\n",
    "# --- Load the blog post into a LangChain Document object ---\n",
    "docs = loader.load()  # Returns a list of one Document, since it's one blog post\n",
    "\n",
    "# --- Check and print the result ---\n",
    "assert len(docs) == 1  # Ensures we got exactly one document\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")  # Prints the total length of the raw page content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "213f5905-a87e-4ebc-af87-07abb65214ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6749723d-d8a9-49d6-9420-b74d069a45d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 66 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter  # Recommended splitter for general use\n",
    "\n",
    "# --- Initialize the text splitter ---\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,        # Max length of each chunk in characters\n",
    "    chunk_overlap=200,      # Overlap between chunks to preserve context at boundaries\n",
    "    add_start_index=True,   # Adds metadata indicating where each chunk starts in the original document\n",
    ")\n",
    "\n",
    "# --- Split the loaded document into smaller chunks ---\n",
    "all_splits = text_splitter.split_documents(docs)  # Returns a list of Document objects\n",
    "\n",
    "# --- Output the number of resulting chunks ---\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bf3a325-ec32-462b-a842-149c28e1b772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['21a85387-d16f-4cf8-b730-cc22ac99aa2d', 'bf4f2851-87c3-45a4-a8e9-4892da63bf5b', '4bec8aec-0f3e-4f0f-955f-445f9e77e914']\n"
     ]
    }
   ],
   "source": [
    "# --- Store the document chunks in the vector store by embedding and indexing them ---\n",
    "\n",
    "# Each chunk from `all_splits` is embedded and stored using the `vector_store` you initialized earlier\n",
    "# The method returns a list of unique document IDs assigned by the store\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Print the first few document IDs to confirm indexing worked\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b870e5c0-33c3-4fe7-9366-39f3ed30f6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub  # LangChain Hub provides shared, versioned prompt templates\n",
    "\n",
    "# --- Pull a reusable RAG prompt template from LangChain Hub ---\n",
    "# This is a predefined prompt specifically designed for Retrieval-Augmented Generation (RAG)\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# --- Fill the prompt template with example values ---\n",
    "# We're just testing here — \"(context goes here)\" and \"(question goes here)\" are placeholders\n",
    "example_messages = prompt.invoke(\n",
    "    {\n",
    "        \"context\": \"(context goes here)\",   # This will eventually be the retrieved document content\n",
    "        \"question\": \"(question goes here)\"  # This will eventually be the user's question\n",
    "    }\n",
    ").to_messages()  # Converts the structured prompt into message format compatible with LLMs\n",
    "\n",
    "# --- Sanity check: Make sure one message was generated ---\n",
    "assert len(example_messages) == 1\n",
    "\n",
    "# --- Print the final message content that will be sent to the LLM ---\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7d5dd80-19d9-4824-b74f-e93059e775cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document  # LangChain's document format\n",
    "from typing_extensions import List, TypedDict  # Used to define structured state\n",
    "\n",
    "# --- Define the application state that moves through LangGraph ---\n",
    "# This tells LangGraph what fields to expect and pass between steps\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str            # The user's input question\n",
    "    context: List[Document]  # Retrieved document chunks (used as context for the model)\n",
    "    answer: str              # Final generated answer from the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d0a51df-f944-4fb6-8e43-2635277a7d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Retrieval Node ---\n",
    "def retrieve(state: State):\n",
    "    # Use the vector store to find documents similar to the question\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}  # Adds 'context' to the state\n",
    "\n",
    "# --- Step 2: Generation Node ---\n",
    "def generate(state: State):\n",
    "    # Combine retrieved documents into a single string for prompt input\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    \n",
    "    # Fill the prompt with the question and context\n",
    "    messages = prompt.invoke({\n",
    "        \"question\": state[\"question\"],\n",
    "        \"context\": docs_content\n",
    "    })\n",
    "    \n",
    "    # Use the chat model to generate an answer\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    return {\"answer\": response.content}  # Adds 'answer' to the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54a37d48-2d2c-42d1-9c70-bd766a07d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph  # Import tools for building LangGraph workflows\n",
    "\n",
    "# --- Build the graph ---\n",
    "# This uses your previously defined State structure and the retrieve/generate functions\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])  # Define the order of steps\n",
    "\n",
    "graph_builder.add_edge(START, \"retrieve\")  # Connect the graph’s entry point to the first step\n",
    "\n",
    "graph = graph_builder.compile()  # Compile the workflow into a runnable object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27cbfc69-4dec-4410-949b-74b7badfabb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display  # Tools to display images in Jupyter\n",
    "\n",
    "# --- Display a flowchart-style diagram of your LangGraph ---\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b515cb31-427f-4e61-911e-18748ccbba60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [Document(id='66dbce2b-308a-4a1c-8ec4-aec1fac8f799', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='4bec8aec-0f3e-4f0f-955f-445f9e77e914', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='35089b13-96db-40e5-944a-78f6353c2a44', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='67879c1d-83d6-4634-9949-df37714b1104', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.')]\n",
      "\n",
      "\n",
      "Answer: Task Decomposition is the process of breaking down a complicated task into smaller, manageable steps, often utilizing techniques like Chain of Thought (CoT) prompting. This approach allows models to think step by step, enhancing their performance on complex tasks. It can be achieved through simple prompting, task-specific instructions, or human inputs.\n"
     ]
    }
   ],
   "source": [
    "# --- Run the RAG pipeline with a test question ---\n",
    "result = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "\n",
    "# --- Print the retrieved context (the text chunks from the document) ---\n",
    "print(f'Context: {result[\"context\"]}\\n\\n')\n",
    "\n",
    "# --- Print the final generated answer from the model ---\n",
    "print(f'Answer: {result[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14e6e885-64dc-478f-921a-c952e7a55e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieve': {'context': [Document(id='66dbce2b-308a-4a1c-8ec4-aec1fac8f799', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='4bec8aec-0f3e-4f0f-955f-445f9e77e914', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='35089b13-96db-40e5-944a-78f6353c2a44', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='67879c1d-83d6-4634-9949-df37714b1104', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': \"Task Decomposition is the process of breaking down complex tasks into smaller, more manageable steps to enhance problem-solving efficiency. It can involve techniques like Chain of Thought (CoT), where models are prompted to think step by step, or utilizing task-specific instructions. This method allows for clearer planning and interpretation of the model's reasoning process.\"}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Stream execution of the RAG app step-by-step using LangGraph ---\n",
    "\n",
    "# This mode lets you see the intermediate results from each step in the graph,\n",
    "# such as the documents retrieved by the 'retrieve' node, followed by the generated answer.\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"},  # Input question\n",
    "    stream_mode=\"updates\"  # Stream updates after each graph step (node)\n",
    "):\n",
    "    # Print each update from the graph (retrieval, then generation)\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ba8cd64-5217-4cff-9fbf-141eb9539567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Task| De|composition| is| the| process| of| breaking| down| a| complex| task| into| smaller|,| more| manageable| steps|.| This| can| be| achieved| through| techniques| like| Chain| of| Thought| (|Co|T|),| which| encourages| models| to| think| step| by| step|,| or| by| using| task|-specific| prompts|.| It| helps| enhance| model| performance| by| clar|ifying| the| reasoning| process| involved| in| tackling| hard| tasks|.||"
     ]
    }
   ],
   "source": [
    "# --- Stream token-level output from the final answer (LLM response) ---\n",
    "\n",
    "# This allows you to simulate real-time typing or streaming in chat-like UIs\n",
    "# Each `message.content` will contain part of the generated answer\n",
    "\n",
    "for message, metadata in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"},  # The input question\n",
    "    stream_mode=\"messages\"  # Stream individual message chunks from the LLM\n",
    "):\n",
    "    print(message.content, end=\"|\")  # Print each token-like chunk, separated by \"|\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59f3bac5-626a-4c79-aec8-0d68e06e4d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate  # Import prompt utility\n",
    "\n",
    "# --- Define your custom RAG prompt ---\n",
    "# This version enforces:\n",
    "# - Conciseness\n",
    "# - No guessing\n",
    "# - A polite tone\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "# --- Create a LangChain PromptTemplate object ---\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "688fb6f0-e51b-4dcd-843c-6f6350ca0da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
       " 'start_index': 8,\n",
       " 'section': 'beginning'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Simulate adding metadata to your document chunks ---\n",
    "# This divides your content into three sections so we can apply filters later\n",
    "\n",
    "total_documents = len(all_splits)      # Total number of document chunks\n",
    "third = total_documents // 3           # Divide into thirds for metadata assignment\n",
    "\n",
    "# Assign a \"section\" label to each document chunk based on its position\n",
    "for i, document in enumerate(all_splits):\n",
    "    if i < third:\n",
    "        document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "\n",
    "# --- Inspect metadata for the first chunk to verify it was applied correctly ---\n",
    "all_splits[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6f2ead9-0626-463a-a292-0e80ecf29229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore  # Import the simple in-memory store\n",
    "\n",
    "# --- Reinitialize the vector store with metadata-enabled document chunks ---\n",
    "vector_store = InMemoryVectorStore(embeddings)  # Pass in your embedding model\n",
    "\n",
    "# --- Re-index all the document splits, now with section metadata ---\n",
    "_ = vector_store.add_documents(all_splits)  # Store new version of docs with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3cb3a14f-5972-4b36-8658-b004359f2c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal  # Used to restrict a field to specific values\n",
    "from typing_extensions import Annotated  # Adds metadata (descriptions) to types\n",
    "\n",
    "# --- Define the structured schema for a search query ---\n",
    "# This will be used to extract structured data from an LLM output\n",
    "\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search query.\"\"\"\n",
    "\n",
    "    # The actual query we will use in similarity search\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "\n",
    "    # Section of the document to filter on (metadata filter)\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"],  # Restrict valid values\n",
    "        ...,  # Required field\n",
    "        \"Section to query.\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d2ab0bf-6fd9-4494-a008-1a727b1f3432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# --- Update your State to include the structured query object ---\n",
    "class State(TypedDict):\n",
    "    question: str                    # Raw user input\n",
    "    query: Search                    # Structured query (with filter)\n",
    "    context: List[Document]         # Retrieved chunks\n",
    "    answer: str                      # Final model output\n",
    "\n",
    "# --- New Step: Analyze the raw question to produce a structured query object ---\n",
    "def analyze_query(state: State):\n",
    "    structured_llm = llm.with_structured_output(Search)  # Tell the LLM to return a structured object\n",
    "    query = structured_llm.invoke(state[\"question\"])     # LLM analyzes the question and returns query + section\n",
    "    return {\"query\": query}                              # Inject this into the graph state\n",
    "\n",
    "# --- Modified Retrieval Step: Uses structured query + metadata filter ---\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]  # Extract structured query\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],  # Use the rewritten/cleaned query string\n",
    "        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"]  # Filter by section metadata\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "# --- Generation Step: Same as before ---\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# --- Update the Graph ---\n",
    "# Add 'analyze_query' as the new first step before retrieval and generation\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")  # Start the graph at the new step\n",
    "graph = graph_builder.compile()  # Compile into an executable workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da4c7523-63df-4927-86e2-c4906c284fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display  # Import tools to display images in Jupyter\n",
    "\n",
    "# --- Visualize your LangGraph as a Mermaid diagram ---\n",
    "# This helps you see the step-by-step flow of your application:\n",
    "# START -> analyze_query -> retrieve -> generate\n",
    "\n",
    "display(\n",
    "    Image(graph.get_graph().draw_mermaid_png())  # Render the graph as a PNG image using Mermaid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7228a2ae-8e51-42ef-9c81-5b0c90efc73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analyze_query': {'query': {'query': 'Task Decomposition', 'section': 'end'}}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'retrieve': {'context': [Document(id='73adfb4f-3203-499c-8268-ce4867880e7a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39220, 'section': 'end'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.'), Document(id='93031887-8846-464c-bf3f-3934bb1fa369', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39085, 'section': 'end'}, page_content='}\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:'), Document(id='8b0c285e-4d6a-49b2-a919-a423b22c1601', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 32941, 'section': 'end'}, page_content='}\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:'), Document(id='d324ff33-138a-49ff-8951-9158d4c4e5bc', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 35126, 'section': 'end'}, page_content='\"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': 'The end of the post highlights that long-term planning and task decomposition continue to face challenges due to the limitations of LLMs. They struggle to adjust plans in response to unexpected errors, making them less adaptable than humans who can learn from trial and error. This points to a need for improved methods in handling complex tasks over extended contexts.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Stream each step in your LangGraph RAG pipeline ---\n",
    "# This shows the intermediate state after each node runs:\n",
    "# - analyze_query: returns structured query with section\n",
    "# - retrieve: returns context chunks based on that section\n",
    "# - generate: returns final LLM-generated answer\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"question\": \"What does the end of the post say about Task Decomposition?\"},  # Input question\n",
    "    stream_mode=\"updates\",  # Stream state updates after each graph node\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")  # Show each step's result, separated visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19ba80-1c3d-4202-9a78-92beb1a2b8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
