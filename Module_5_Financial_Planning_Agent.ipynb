{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "330d6caf-c08d-45f5-8596-0288cca9e36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.3.13 in /opt/anaconda3/lib/python3.12/site-packages (0.3.13)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain==0.3.13) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain==0.3.13) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain==0.3.13) (3.10.5)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.26 in /opt/anaconda3/lib/python3.12/site-packages (from langchain==0.3.13) (0.3.56)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain==0.3.13) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /opt/anaconda3/lib/python3.12/site-packages (from langchain==0.3.13) (0.2.11)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain==0.3.13) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain==0.3.13) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain==0.3.13) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain==0.3.13) (8.2.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.13) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.13) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.13) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.13) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.13) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.13) (1.11.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.26->langchain==0.3.13) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.26->langchain==0.3.13) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.26->langchain==0.3.13) (4.11.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.13) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.13) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.13) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.13) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.13) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.13) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.13) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.13) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.13) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.13) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.13) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.13) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.13) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.26->langchain==0.3.13) (2.1)\n",
      "Requirement already satisfied: langgraph==0.2.60 in /opt/anaconda3/lib/python3.12/site-packages (0.2.60)\n",
      "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph==0.2.60) (0.3.56)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.4 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph==0.2.60) (2.0.24)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph==0.2.60) (0.1.61)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (0.2.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (4.11.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (2.8.2)\n",
      "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph==0.2.60) (1.9.1)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.60) (0.27.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.60) (3.10.16)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.60) (4.2.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.60) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.60) (1.0.2)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.60) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.60) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.60) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (2.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (2.2.3)\n",
      "Requirement already satisfied: openai==1.58.1 in /opt/anaconda3/lib/python3.12/site-packages (1.58.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai==1.58.1) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai==1.58.1) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai==1.58.1) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai==1.58.1) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai==1.58.1) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai==1.58.1) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.12/site-packages (from openai==1.58.1) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.12/site-packages (from openai==1.58.1) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai==1.58.1) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai==1.58.1) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai==1.58.1) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.58.1) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai==1.58.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai==1.58.1) (2.20.1)\n"
     ]
    }
   ],
   "source": [
    "# Install LangChain version 0.3.13\n",
    "# LangChain connects LLMs to external tools like vector databases, document loaders, and APIs\n",
    "!pip install langchain==0.3.13\n",
    "\n",
    "# Install LangGraph version 0.2.60\n",
    "# LangGraph lets you create agent workflows (graphs) on top of LangChain\n",
    "!pip install langgraph==0.2.60\n",
    "\n",
    "# Install OpenAI Python client version 1.58.1\n",
    "# This library allows your Python code to interact with OpenAI models like GPT-4\n",
    "!pip install openai==1.58.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6158650f-c872-4dcf-a273-72cfa29ff483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key:  ········\n",
      "Enter your LangChain API key (if you have one):  ········\n",
      "Enter your Tavily API key (if using):  ········\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for working with environment variables and securely entering API keys\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "# Required: Set your OpenAI API key so that LangChain can access GPT models\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# Optional: Set your LangChain API key if you're using LangSmith for tracing/debugging (not required for this project)\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangChain API key (if you have one): \")\n",
    "\n",
    "# Optional but recommended: Turn on LangChain tracing for better debugging and visualization\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "# Optional: Set your Tavily API key if you plan to use web search (not required for this Fidelity project)\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key (if using): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4b1b249-451a-42c3-ad38-e60e8f87cc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Import Required Libraries and Set Up Environment\n",
    "# ---------------------------------------\n",
    "\n",
    "# LangChain components for models, embeddings, prompting, document loading, and vector storage\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings  # For OpenAI LLM and embedding generation\n",
    "from langchain.prompts import ChatPromptTemplate  # For creating prompt templates\n",
    "from langchain_community.document_loaders import WebBaseLoader  # For loading content from URLs\n",
    "from langchain_community.vectorstores import Chroma  # For storing text embeddings in a vector store\n",
    "\n",
    "# LangGraph core for building AI agent workflows as graphs\n",
    "import langgraph\n",
    "from langgraph.graph import StateGraph, END  # StateGraph builds the flow, END marks the final node\n",
    "\n",
    "# Python standard libraries\n",
    "from typing import TypedDict, Annotated  # For defining custom types (used in LangGraph state)\n",
    "import os  # For setting environment variables\n",
    "\n",
    "# ---------------------------------------\n",
    "# Set Headers for Web Page Access\n",
    "# ---------------------------------------\n",
    "\n",
    "# Some websites (like Fidelity) require a real User-Agent header to allow scraping\n",
    "# Set a User-Agent string to mimic a browser and avoid getting blocked\n",
    "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\"\n",
    "os.environ[\"USER_AGENT\"] = user_agent  # Useful for consistent access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60797d64-816b-404c-8b6d-55120fa696e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document(s).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "How much do I need to retire? | Fidelity\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to Main Content.\n",
      "Site navigation\n",
      "\n",
      "Fidelity.com Home\n",
      "Fidelity.com Home\n",
      " \n",
      "\n",
      "Customer Service\n",
      "\n",
      "Profile\n",
      "\n",
      "\n",
      "Open an Account\n",
      "\n",
      "Fidelity Assistant\n",
      "Log In\n",
      "\n",
      "Customer Service\n",
      "\n",
      "Profile\n",
      "\n",
      "\n",
      "Open an Account\n",
      "\n",
      "Fidelity Assistant\n",
      "Log Out\n",
      " \n",
      "\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Accounts & Trade\n",
      "\n",
      "\n",
      "Portfolio Log In Required\n",
      "Portfolio\n",
      "AccountPositions Log In Required\n",
      "AccountPositions\n",
      "Trade Log In Required\n",
      "Trade\n",
      "Trading D\n"
     ]
    }
   ],
   "source": [
    "# Load the Fidelity \"How Much Do I Need to Retire?\" webpage using WebBaseLoader\n",
    "\n",
    "# Create a loader for the Fidelity retirement article\n",
    "loader = WebBaseLoader(\"https://www.fidelity.com/viewpoints/retirement/how-much-do-i-need-to-retire\")\n",
    "\n",
    "# Load the webpage content into a list of documents\n",
    "documents = loader.load()\n",
    "\n",
    "# Optional: print out how many documents were loaded and a sample of the content\n",
    "print(f\"Loaded {len(documents)} document(s).\")\n",
    "print(documents[0].page_content[:500])  # Show first 500 characters of the first document to see what we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd1e50d5-9264-4c34-9b65-2ae74e764fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document successfully stored in Chroma vector store.\n"
     ]
    }
   ],
   "source": [
    "# Store the loaded document into a Chroma vector store\n",
    "\n",
    "# What is a Chroma vector store?\n",
    "# ---------------------------------------\n",
    "# Chroma is a database specifically designed to store \"embeddings.\"\n",
    "# An embedding is a numerical representation (vector) of a chunk of text,\n",
    "# where similar texts are mapped to nearby points in a mathematical space.\n",
    "# \n",
    "# Why do we use it?\n",
    "# It lets the AI agent perform \"semantic search\" — meaning it can\n",
    "# find relevant information based on the meaning of a user's question,\n",
    "# not just exact keyword matching.\n",
    "\n",
    "# Step 1: Create an embeddings object using OpenAIEmbeddings\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "# Step 2: Create the Chroma vector store and insert the loaded documents\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents,             # List of documents we loaded from Fidelity\n",
    "    embedding_function     # Function that turns documents into vectors\n",
    ")\n",
    "\n",
    "# Now your document is stored inside Chroma and ready for semantic search!\n",
    "print(\"Document successfully stored in Chroma vector store.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c5772f2-0273-417f-aa4c-55a16e188d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever tool successfully created and ready. (Fetching up to 1 documents)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# Create a retriever tool from the Chroma vector store (improved version)\n",
    "# ---------------------------------------\n",
    "\n",
    "# What is a retriever?\n",
    "# ---------------------\n",
    "# A retriever is like a search engine for your vector store (Chroma).\n",
    "# It takes a user's question, finds the most relevant chunks of information\n",
    "# from the documents, and returns them.\n",
    "\n",
    "# Step 1: Create a retriever from the Chroma vectorstore\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Step 2: Customize retriever settings\n",
    "# Automatically set 'k' to be no more than the number of documents loaded\n",
    "num_docs_loaded = len(documents)\n",
    "retriever.search_kwargs = {\"k\": min(3, num_docs_loaded)}  # Fetch up to 3 documents, or fewer if less available\n",
    "\n",
    "print(f\"Retriever tool successfully created and ready. (Fetching up to {retriever.search_kwargs['k']} documents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "706abf83-0404-4d4b-9925-b80f597b7791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever tool wrapped and ready for use by the AI agent.\n"
     ]
    }
   ],
   "source": [
    "# Import Tool class\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "# Create a retriever tool\n",
    "retriever_tool = Tool(\n",
    "    name=\"fidelity_retriever\",  # Name for the tool\n",
    "    description=\"Use this tool to search for retirement information from Fidelity documents.\",\n",
    "    func=retriever.invoke  # This links the retriever's \"search\" ability to the tool\n",
    ")\n",
    "\n",
    "print(\"Retriever tool wrapped and ready for use by the AI agent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0114b641-5dbc-496b-b800-823ecf659e0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance-checking chain (RunnableSequence) created successfully.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# Create the PromptTemplate and Relevance Checking Chain\n",
    "# ---------------------------------------\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Step 1: Define a prompt template that tells the LLM how to judge relevance\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a financial advisor specializing in retirement planning.\n",
    "\n",
    "Here is the retrieved document:\n",
    "{context}\n",
    "\n",
    "Here is the user's question:\n",
    "{question}\n",
    "\n",
    "Please do the following:\n",
    "- State \"YES\" if the document provides information that could directly or indirectly answer the user's question.\n",
    "- State \"NO\" if the document is unrelated or off-topic.\n",
    "- Briefly explain in exactly one sentence why you scored it YES or NO.\n",
    "- Highlight a key phrase or idea from the document that supports your decision.\n",
    "Respond very concisely.\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# Step 2: Initialize the OpenAI LLM model you will use\n",
    "# Corrected: Using GPT-4o-mini (new model)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Step 3: Chain the prompt directly into the LLM using the modern RunnableSequence style\n",
    "relevance_chain = prompt | llm\n",
    "\n",
    "print(\"Relevance-checking chain (RunnableSequence) created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb748009-81eb-4d4b-a925-3c12a34ae01a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Block 1: Node Definitions\n",
    "# -----------------------------\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from typing import TypedDict\n",
    "\n",
    "# Define the structure of shared state passed between nodes\n",
    "class AgentState(TypedDict):\n",
    "    messages: list          # Chat history or user questions\n",
    "    context: str            # Retrieved document content\n",
    "    relevance_result: str   # 'yes' or 'no' from the relevance checker\n",
    "    answer: str             # Final response from the agent\n",
    "\n",
    "# Node 1: Retrieve relevant documents from Chroma\n",
    "def retrieve_node(state: dict):\n",
    "    question = state[\"messages\"][-1][1]\n",
    "    docs = retriever.invoke(question)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    return {\"context\": context}\n",
    "\n",
    "# Node 2: Use the relevance chain to check if context is useful\n",
    "def relevance_check_node(state: dict):\n",
    "    question = state[\"messages\"][-1][1]\n",
    "    context = state[\"context\"]\n",
    "    result = relevance_chain.invoke({\"context\": context, \"question\": question})\n",
    "    return {\"relevance_result\": result.content.strip().lower()}\n",
    "\n",
    "# Node 3: Generate a final answer using the context\n",
    "# NOTE: Updated to match tutorial's expected structure\n",
    "\n",
    "def generate_answer_node(state: dict):\n",
    "    question = state[\"messages\"][-1][1]\n",
    "    context = state[\"context\"]\n",
    "    prompt = f\"\"\"You are a Fidelity financial advisor. Use the context below to answer the user's question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"answer\": {\"messages\": [response.content.strip()]}}\n",
    "\n",
    "# Node 4: Fallback if nothing relevant was found\n",
    "\n",
    "def no_answer_node(state: dict):\n",
    "    return {\"answer\": {\"messages\": [\"I'm sorry, I couldn't find relevant information to answer your question.\"]}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cfe8d2a-d6f3-4528-bbc3-972381d8c099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph agent compiled successfully.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# Build the LangGraph Agent (continued)\n",
    "# ---------------------------------------\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Initialize the LangGraph using the defined AgentState type\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# Register each node (function) in the agent workflow\n",
    "# Each node is a step in the AI agent's reasoning pipeline\n",
    "graph.add_node(\"retrieve\", RunnableLambda(retrieve_node))\n",
    "graph.add_node(\"check_relevance\", RunnableLambda(relevance_check_node))\n",
    "graph.add_node(\"generate_answer\", RunnableLambda(generate_answer_node))\n",
    "graph.add_node(\"no_answer\", RunnableLambda(no_answer_node))\n",
    "\n",
    "# Set the starting point of the graph — always begins with document retrieval\n",
    "graph.set_entry_point(\"retrieve\")\n",
    "\n",
    "# Define how the graph flows between nodes\n",
    "# After retrieving, check if the retrieved docs are relevant\n",
    "graph.add_edge(\"retrieve\", \"check_relevance\")\n",
    "\n",
    "# Conditional routing logic — send to answer node only if relevant\n",
    "# Otherwise go to fallback response\n",
    "\n",
    "def route_based_on_relevance(state: AgentState):\n",
    "    return \"generate_answer\" if \"yes\" in state[\"relevance_result\"] else \"no_answer\"\n",
    "\n",
    "graph.add_conditional_edges(\"check_relevance\", route_based_on_relevance)\n",
    "\n",
    "# Define terminal nodes — the end of the line for each branch\n",
    "graph.add_edge(\"generate_answer\", END)\n",
    "graph.add_edge(\"no_answer\", END)\n",
    "\n",
    "# Compile the defined state graph into an executable AI agent\n",
    "agent = graph.compile()\n",
    "\n",
    "print(\"LangGraph agent compiled successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0cd19f84-944d-40a7-8578-959cad0cf240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Answer ===\n",
      "{'messages': [\"To determine how much you need to save for retirement, follow these steps:\\n\\n1. **Assess Your Current Financial Situation**: Start by evaluating your current income, expenses, savings, and investments. This will give you a clear picture of where you stand financially.\\n\\n2. **Define Your Retirement Goals**: Consider when you want to retire and what kind of lifestyle you envision. Will your expenses decrease, remain the same, or increase in retirement? This will impact how much you need to save.\\n\\n3. **Use Fidelity's Guidelines**: Aim to save at least:\\n   - 1x your salary by age 30\\n   - 3x by age 40\\n   - 6x by age 50\\n   - 8x by age 60\\n   - 10x by age 67\\n\\n   These milestones can serve as goalposts to help you plan your savings.\\n\\n4. **Calculate Your Income Needs**: Estimate how much income you will need in retirement. A common guideline is to plan for your savings to replace about 45% of your pretax, preretirement income. Adjust this percentage based on your expected lifestyle (below average, average, or above average).\\n\\n5. **Determine Your Savings Rate**: Research suggests saving at least 15% of your income annually, including any employer contributions. This can help you accumulate the necessary savings by your target retirement age.\\n\\n6. **Consider Delaying Retirement**: If possible, consider postponing your retirement. Delaying can reduce the amount you need to save, as it allows your savings to grow longer and reduces the number of years you will need to draw from your savings.\\n\\n7. **Plan for Withdrawals**: Once you retire, aim for a sustainable withdrawal rate of no more than 4% to 5% of your savings annually, adjusting for inflation. This will help ensure your savings last throughout your retirement.\\n\\n8. **Review and Adjust Regularly**: Your financial situation and goals may change over time, so it’s important to review your retirement plan regularly and make adjustments as needed.\\n\\n9. **Seek Professional Advice**: If you're unsure about your calculations or need personalized guidance, consider consulting a financial advisor who can help you create a tailored retirement plan.\\n\\nBy following these steps, you can develop a clearer understanding of how much you need to save for a comfortable retirement.\"]}\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# Send a Sample Prompt to Your Graph and Print the Result\n",
    "# ---------------------------------------\n",
    "\n",
    "# Step 1: Define the input — simulating a user asking a retirement planning question\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"What are the steps that I should take to determine how much I need to save for retirement?\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Step 2: Run the compiled LangGraph agent using that input\n",
    "result = agent.invoke(inputs)\n",
    "\n",
    "# Step 3: Show the final response generated by the agent\n",
    "print(\"=== Final Answer ===\")\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5cbb04b2-7f46-4f0a-b1da-2e0a3058ece4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Answer ===\n",
      "{'messages': [\"According to Fidelity's guidelines, by age 33, you should aim to have saved at least 1x your annual salary for retirement. This means if you earn $50,000 a year, you should have approximately $50,000 saved by age 33. \\n\\nKeep in mind that this is a general guideline, and your personal savings goal may vary based on factors such as your desired retirement lifestyle and when you plan to retire. If you have specific retirement goals or lifestyle expectations, you may want to adjust your savings target accordingly.\"]}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"How much should I have saved by the time I’m 33 if I want to retire comfortably?\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Run the agent\n",
    "result = agent.invoke(inputs)\n",
    "\n",
    "# Show the result\n",
    "print(\"=== Final Answer ===\")\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b24fe56f-2eca-4549-875d-45e70a740672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Answer ===\n",
      "{'messages': [\"I'm sorry, I couldn't find relevant information to answer your question.\"]}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"Who won the NBA championship in 2023?\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Run the agent\n",
    "result = agent.invoke(inputs)\n",
    "\n",
    "# Show the result\n",
    "print(\"=== Final Answer ===\")\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "39e9dae4-b50b-461d-84af-93773108f6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.25.5-cp39-abi3-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.25.5-cp39-abi3-macosx_11_0_arm64.whl (18.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.6/18.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.25.5\n",
      "Loaded 6 pages from PDF.\n",
      "Allocation\n",
      "Fidelity Freedom® 2045 Fund (FFFGX)\n",
      "  No Transaction Fee4 \n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "0.00\n",
      "0.00\n",
      "0.00\n",
      "0.00\n",
      "0.00\n",
      "0.00\n",
      "0.00\n",
      "0.00\n",
      "0.00\n",
      "0.00\n",
      "9000.00\n",
      "12000.00\n",
      "15000.00\n",
      "18000.00\n",
      "21000.00\n",
      "24000.00\n",
      "27000.00\n",
      "30000.00\n",
      "33000.00\n",
      "36000.00\n",
      "9.00K\n",
      "12.00K\n",
      "15.00K\n",
      "18.00K\n",
      "21.00K\n",
      "24.00K\n",
      "27.00K\n",
      "30.00K\n",
      "33.00K\n",
      "36.00K\n",
      "Average Annual Total Returns\n",
      "Hypothetical Growth of $10,0006,7\n",
      "AS OF 11/30/2024 ;  Target-Date 2045\n",
      " FFFGX : $23,898     \n",
      " S&P 500 Index : $35,002     \n",
      " Target-Date 2045 : \n"
     ]
    }
   ],
   "source": [
    "# Install PyMuPDF if you haven't already\n",
    "!pip install pymupdf\n",
    "\n",
    "# Import required libraries\n",
    "import fitz  # PyMuPDF\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Path to your PDF file\n",
    "pdf_path = '/Users/daniel/Documents/Northwestern/MSDS-442 AI Agent Design & Development/Assignment_1/FFFGX.pdf'\n",
    "\n",
    "# Load the PDF and extract text\n",
    "def load_pdf_with_pymupdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    documents = []\n",
    "    for page_num, page in enumerate(doc, start=1):\n",
    "        text = page.get_text()\n",
    "        if text.strip():  # skip empty pages\n",
    "            documents.append(Document(page_content=text, metadata={\"page\": page_num}))\n",
    "    doc.close()\n",
    "    return documents\n",
    "\n",
    "# Load the PDF\n",
    "pdf_documents = load_pdf_with_pymupdf(pdf_path)\n",
    "\n",
    "# Check how many pages were loaded\n",
    "print(f\"Loaded {len(pdf_documents)} pages from PDF.\")\n",
    "print(pdf_documents[0].page_content[:500])  # Print first 500 chars of page 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9db9b01-c6ce-4ce2-8b05-8a9a8699fe9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF document successfully stored in Chroma vector store and retriever is ready.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# Create a New Vector Store from the Loaded PDF\n",
    "# ---------------------------------------\n",
    "\n",
    "# Step 1: Create an embeddings object\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "# Step 2: Create a Chroma vector store with the PDF pages\n",
    "pdf_vectorstore = Chroma.from_documents(\n",
    "    pdf_documents,           # documents loaded from the Fidelity Freedom 2045 PDF\n",
    "    embedding_function       # embedding function\n",
    ")\n",
    "\n",
    "# Step 3: Create a retriever from the PDF vectorstore\n",
    "pdf_retriever = pdf_vectorstore.as_retriever()\n",
    "pdf_retriever.search_kwargs = {\"k\": 3}  # fetch top 3 relevant chunks\n",
    "\n",
    "print(\"PDF document successfully stored in Chroma vector store and retriever is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06069b54-aff8-434e-a2b7-3aa5e3e69f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Answer ===\n",
      "The name of the fund is Fidelity Freedom® 2045 Fund.\n",
      "\n",
      "=== Answer ===\n",
      "The document does not explicitly mention the name of the fund manager. However, it states that Fidelity Management & Research Company LLC is the Adviser responsible for managing the fund.\n",
      "\n",
      "=== Answer ===\n",
      "The calendar year return for 2022 for the Fidelity Freedom® 2045 Fund was -18.26%, and for the S&P 500, it was -18.11%.\n",
      "\n",
      "=== Answer ===\n",
      "The document does not explicitly state the exact value of the Portfolio Net Assets. However, Portfolio Net Assets are defined as the difference between a portfolio's total assets and liabilities, including all share classes of the fund. To find the specific value, you would typically need to refer to the fund's financial statements or a detailed report that includes this information.\n",
      "\n",
      "=== Answer ===\n",
      "The Morningstar rating for this fund is not explicitly stated in the provided context. However, the context does mention that the fund is rated within the Morningstar Category: Target-Date 2045. The number of funds used to rate this fund is as follows:\n",
      "\n",
      "- Overall: Out of 188 funds\n",
      "- 3 Years: Out of 188 funds\n",
      "- 5 Years: Out of 164 funds\n",
      "- 10 Years: Out of 109 funds\n",
      "\n",
      "The specific star rating (e.g., 5 stars, 4 stars) is not provided in the context.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# Set Up Chat Model\n",
    "# ---------------------------------------\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Use a model (you already know GPT-4o works fine)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# ---------------------------------------\n",
    "# Define a Function to Ask Questions Based on PDF\n",
    "# ---------------------------------------\n",
    "\n",
    "def ask_pdf_question(question):\n",
    "    # Retrieve relevant pages\n",
    "    docs = pdf_retriever.invoke(question)\n",
    "    \n",
    "    # Combine content from retrieved documents\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    # Format the message\n",
    "    message = HumanMessage(content=f\"\"\"You are analyzing a Fidelity fund document.\n",
    "Use the below context to answer the question:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\")\n",
    "    \n",
    "    # Get the model's answer\n",
    "    response = llm.invoke([message])\n",
    "    \n",
    "    # Print the answer\n",
    "    print(\"\\n=== Answer ===\")\n",
    "    print(response.content)\n",
    "\n",
    "# ---------------------------------------\n",
    "# Now you can call ask_pdf_question() with each prompt\n",
    "# ---------------------------------------\n",
    "\n",
    "# Example questions the tutorial gave you:\n",
    "\n",
    "ask_pdf_question(\"What is the name of this fund?\")\n",
    "ask_pdf_question(\"Who is the fund manager?\")\n",
    "ask_pdf_question(\"What is the calendar year return for 2022 for this fund and S&P 500?\")\n",
    "ask_pdf_question(\"What is the Portfolio Net Assets?\")\n",
    "ask_pdf_question(\"What is the Morningstar rating for this fund? How many funds used to rate this fund?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f25ddf-d58c-4c2d-9691-b1c380b14a22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
