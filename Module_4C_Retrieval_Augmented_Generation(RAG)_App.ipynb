{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8834527d-27c8-4cea-ba21-49f5d4f85bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key:  ········\n",
      "Enter your LangSmith API key (or press Enter to skip):  ········\n",
      "Enter your Tavily API key (or press Enter to skip):  ········\n"
     ]
    }
   ],
   "source": [
    "# --- Secure API Key Setup ---\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "# Required: OpenAI API Key\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# Optional: Enable LangChain tracing via LangSmith (for debugging / observability)\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key (or press Enter to skip): \")\n",
    "\n",
    "# Optional: Tavily key (useful if you decide to do web search augmentation later)\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key (or press Enter to skip): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8ab5ab6-018d-42e9-884d-01a2c9355f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the chat model for response generation\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae9277a-ac1f-49a2-b088-778debafb901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Initialize the OpenAI embeddings model\n",
    "# This will be used to embed your document chunks and user queries\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9cb5e9a-ce49-413f-b181-37369db67078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "# Initialize an in-memory vector store using the OpenAI embeddings model\n",
    "# This store will hold your embedded document chunks for retrieval\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e3d7f63-ffc7-4ef5-be7f-8010aeb557bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --upgrade --quiet langgraph langchain-community beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f32f6108-1ec3-4063-bc21-c3862b7b2bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4  # Used to filter and parse HTML\n",
    "from langchain import hub  # For pulling prebuilt prompts later\n",
    "from langchain_community.document_loaders import WebBaseLoader  # Loads website content\n",
    "from langchain_core.documents import Document  # LangChain document format\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter  # Breaks text into chunks\n",
    "from typing_extensions import List, TypedDict  # For later use in state typing\n",
    "\n",
    "# --- Load the blog post from Lilian Weng’s site ---\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),  # URL to load\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(  # Filter out only these HTML elements\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()  # Load the web page into a list of Document objects\n",
    "\n",
    "# --- Split the document into manageable chunks ---\n",
    "# Chunks will be used for embedding and vector search\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,        # Max characters per chunk\n",
    "    chunk_overlap=200       # Overlap between chunks to preserve context\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)  # Final list of chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d53d6046-d059-4898-9b1f-04c47e8565c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Add the split blog post chunks to your vector store ---\n",
    "# This indexes them so they can be retrieved during similarity search\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efde0446-c2dc-4889-a4ea-cbad5aa1a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "# --- Initialize a LangGraph builder using MessagesState ---\n",
    "# This state automatically handles a sequence of messages\n",
    "# including user input, LLM responses, tool calls, and tool outputs\n",
    "graph_builder = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9910ca3-00bf-4355-9cf2-c84ace2aefe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# --- Define a retrieval tool that the LLM can call during a conversation ---\n",
    "@tool(response_format=\"content_and_artifact\")  # Return both readable text and structured data\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    \n",
    "    # Perform semantic search over the indexed document chunks\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    \n",
    "    # Create a readable summary of results for the model to work with\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        f\"Source: {doc.metadata}\\nContent: {doc.page_content}\"\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    \n",
    "    # Return both the summary and the actual documents\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce98034f-248e-4229-ba71-08a4d20abc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage  # Used to create system-level prompts\n",
    "from langgraph.prebuilt import ToolNode  # Handles tool execution and state tracking\n",
    "\n",
    "# --- Step 1: Generate a response or tool call using the LLM ---\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate a tool call for retrieval OR directly respond to the user.\"\"\"\n",
    "    \n",
    "    # Bind the retrieval tool so the LLM can choose to call it\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    \n",
    "    # Invoke the LLM on the message history — may return an answer OR a tool call\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    \n",
    "    # Return the new AIMessage and append it to the state\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# --- Step 2: Execute the retrieval tool, if it was called ---\n",
    "# ToolNode automatically runs the tool and adds its output to the message state as a ToolMessage\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "# --- Step 3: Generate a final answer using the retrieved content ---\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate the final answer using context from ToolMessages.\"\"\"\n",
    "    \n",
    "    # Extract only the most recent ToolMessages (retrieved docs)\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]  # Keep in original order\n",
    "\n",
    "    # Format ToolMessages into readable context for the LLM\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    \n",
    "    # Create a system prompt guiding the model to answer concisely using the retrieved context\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer the question. \"\n",
    "        \"If you don't know the answer, say that you don't know. \"\n",
    "        \"Use three sentences maximum and keep the answer concise.\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    \n",
    "    # Keep relevant message history (human, system, and AI without tool calls)\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    \n",
    "    # Create the prompt for the LLM using system + user messages\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Generate the final answer from the model\n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    # Return the message to append to chat history\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5dc8950a-5f1e-43f1-8365-aaacae97cd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "# --- Add nodes to the graph ---\n",
    "# Each node corresponds to a stage in the RAG pipeline\n",
    "graph_builder.add_node(query_or_respond)  # Step 1: Model generates tool call or direct response\n",
    "graph_builder.add_node(tools)             # Step 2: If tool was called, run it (retrieval)\n",
    "graph_builder.add_node(generate)          # Step 3: Final answer generation using retrieved context\n",
    "\n",
    "# --- Define the starting point of the graph ---\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "\n",
    "# --- Conditional logic for tool execution ---\n",
    "# If the model calls a tool, go to \"tools\"\n",
    "# If not, the chain ends directly with the initial response\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,  # This built-in condition checks for tool calls in the AIMessage\n",
    "    {\n",
    "        END: END,      # No tool call? End the graph here.\n",
    "        \"tools\": \"tools\",  # Tool call detected? Run the tool.\n",
    "    },\n",
    ")\n",
    "\n",
    "# --- Final transition: after retrieval, generate the final answer, then end the graph ---\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "# --- Compile the graph into a callable app ---\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbca9141-332b-4a40-896e-f782b4f9ca7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Render and display a visual diagram of your LangGraph structure\n",
    "# This is helpful to understand the flow between nodes and how conditions route the graph\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0656c3dc-bdd2-4fb5-b7e6-7ca4dd93398a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is Task Decomposition?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_SzwI2vVImS6P7OUjomlLl4Um)\n",
      " Call ID: call_SzwI2vVImS6P7OUjomlLl4Um\n",
      "  Args:\n",
      "    query: Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task decomposition is the process of breaking down a complicated task into smaller, more manageable steps. It often involves using techniques like Chain of Thought (CoT) to enhance model performance by guiding the model to think step by step. This method helps clarify the model’s reasoning and makes complex tasks easier to tackle.\n"
     ]
    }
   ],
   "source": [
    "# Define the user's input message\n",
    "input_message = \"What is Task Decomposition?\"\n",
    "\n",
    "# Stream the conversation step-by-step through the LangGraph\n",
    "# This will show each step in the workflow (tool call, retrieval, final answer, etc.)\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},  # Initial input wrapped as message\n",
    "    stream_mode=\"values\",  # Only the message values (no metadata)\n",
    "):\n",
    "    # Display the final message from each step (pretty-printed for readability)\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da8f0664-3420-44b6-85c9-0121af0a304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver  # In-memory storage for chat state\n",
    "\n",
    "# Create a memory checkpointer (in-memory version)\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Recompile the graph with memory support enabled\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# Assign a unique thread ID for the conversation (helps track history)\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "938c1ce6-aa65-46ac-9ff8-9aaf3d012a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is Task Decomposition?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_87IAkl9fpRN98kKr0dmfgKXo)\n",
      " Call ID: call_87IAkl9fpRN98kKr0dmfgKXo\n",
      "  Args:\n",
      "    query: Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task Decomposition is the process of breaking down a complicated task into smaller, manageable steps. It often involves techniques like Chain of Thought (CoT), which encourages the model to think step by step, and can also be conducted through simple prompting or human inputs. This method enhances performance by transforming complex tasks into simpler ones, allowing for clearer reasoning and execution.\n"
     ]
    }
   ],
   "source": [
    "# User input (first message in the conversation)\n",
    "input_message = \"What is Task Decomposition?\"\n",
    "\n",
    "# Stream the graph step-by-step, now with memory enabled\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},  # Initial message\n",
    "    stream_mode=\"values\",  # Only return message values (not full metadata)\n",
    "    config=config,  # Include conversation thread ID for memory\n",
    "):\n",
    "    # Print the final message at each step\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68534183-adcb-40aa-ac55-3f5c51577142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you look up some common ways of doing it?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_B7wlc2GruujXT0ovp4ZvbRR3)\n",
      " Call ID: call_B7wlc2GruujXT0ovp4ZvbRR3\n",
      "  Args:\n",
      "    query: common methods of task decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Common ways of performing Task Decomposition include: (1) using large language models (LLMs) with simple prompts like \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\", (2) applying task-specific instructions, such as \"Write a story outline\" for creative tasks, and (3) incorporating human inputs to specify the necessary steps. These methods help to clarify and organize the thought process involved in complex tasks.\n"
     ]
    }
   ],
   "source": [
    "# Follow-up question, relying on memory from previous conversation turns\n",
    "input_message = \"Can you look up some common ways of doing it?\"\n",
    "\n",
    "# Stream the response from the graph, using the same thread_id\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},  # Follow-up message\n",
    "    stream_mode=\"values\",  # Return message content only\n",
    "    config=config,  # Use the same conversation ID for memory\n",
    "):\n",
    "    # Show the final message generated at this step\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8b32687b-48db-4197-a6d5-f437dfe04eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Create a ReAct-style agent executor using your LLM and tools\n",
    "# This agent can call `retrieve` multiple times if needed\n",
    "# It uses the same memory so conversation history is preserved\n",
    "agent_executor = create_react_agent(llm, [retrieve], checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84e250fb-f1fd-426d-9525-90c9442da733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Visualize the structure of the agent's execution graph\n",
    "# This helps you understand how the agent decides between thinking, tool use, and final response\n",
    "display(Image(agent_executor.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c3b5f6f-6658-4e93-9fd5-6a481507cec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the standard method for Task Decomposition?\n",
      "\n",
      "Once you get the answer, look up common extensions of that method.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_ESiNv4Px6UnNxaYjV51Zxe6M)\n",
      " Call ID: call_ESiNv4Px6UnNxaYjV51Zxe6M\n",
      "  Args:\n",
      "    query: standard method for Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_QwKbiP6QZTUx5ZpRzZvWOm7R)\n",
      " Call ID: call_QwKbiP6QZTUx5ZpRzZvWOm7R\n",
      "  Args:\n",
      "    query: common extensions of Task Decomposition method\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "### Standard Method for Task Decomposition\n",
      "\n",
      "The standard method for task decomposition involves several approaches, with one prominent technique being Chain of Thought (CoT). This method allows models to break down complex tasks into manageable steps by prompting them to “think step by step.” This approach enhances the performance of models on complicated tasks, making it easier to interpret their reasoning process. Here are the main methods of task decomposition:\n",
      "\n",
      "1. **Prompting Techniques**:\n",
      "   - Basic prompts such as \"Steps for XYZ.\\n1.\" or \"What are the subgoals for achieving XYZ?\" can guide a model to decompose tasks.\n",
      "   - Task-specific instructions, like \"Write a story outline,\" can be used for particular types of tasks.\n",
      "\n",
      "2. **Human Inputs**: This method involves directing how a task may be broken down through human-defined parameters.\n",
      "\n",
      "### Common Extensions of Task Decomposition Method\n",
      "\n",
      "1. **Tree of Thoughts (ToT)**:\n",
      "   - Developed by Yao et al. in 2023, this method extends CoT by allowing multiple reasoning possibilities at each step. \n",
      "   - It creates a tree structure where each issue is broken down into multiple thought steps, allowing for diverse pathways and solutions.\n",
      "   - The exploration within this tree can utilize search strategies like breadth-first search (BFS) or depth-first search (DFS), assessing each state with classifiers or voting mechanisms.\n",
      "\n",
      "Overall, task decomposition is essential for managing complex tasks, and extensions like the Tree of Thoughts provide enhanced capabilities for exploring multiple reasoning avenues.\n"
     ]
    }
   ],
   "source": [
    "# Define a new thread ID to track this conversation separately\n",
    "config = {\"configurable\": {\"thread_id\": \"def234\"}}\n",
    "\n",
    "# Multi-step user question that encourages iteration\n",
    "input_message = (\n",
    "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
    "    \"Once you get the answer, look up common extensions of that method.\"\n",
    ")\n",
    "\n",
    "# Stream each step of the agent's reasoning and actions\n",
    "for event in agent_executor.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},  # Input message\n",
    "    stream_mode=\"values\",  # Show messages only\n",
    "    config=config,  # Maintain history with unique thread ID\n",
    "):\n",
    "    # Print the last message at each stage of the agent's execution\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57f347a4-3c15-4685-9bb0-5aaac9550a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the standard method for Task Decomposition?\n",
      "\n",
      "Once you get the answer, look up common extensions of that method.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_h7srln4UCjQPxRrbw3e67Xuw)\n",
      " Call ID: call_h7srln4UCjQPxRrbw3e67Xuw\n",
      "  Args:\n",
      "    query: standard method for Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_LJrGomhkNUw4Rx2mR5n53oCs)\n",
      " Call ID: call_LJrGomhkNUw4Rx2mR5n53oCs\n",
      "  Args:\n",
      "    query: common extensions of Task Decomposition method\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "### Standard Method for Task Decomposition\n",
      "\n",
      "The standard method for task decomposition is primarily based on the **Chain of Thought (CoT)** technique. This method allows for breaking down complex tasks into simpler, manageable steps through prompting that encourages models to “think step by step.” This approach not only aids in enhancing model performance but also offers clarity into the decision-making process. The key elements of this method include:\n",
      "\n",
      "1. **Step-by-Step Reasoning**: Tasks are structured into smaller components, making them easier to tackle.\n",
      "2. **Prompts**: Simple prompts or task-specific instructions guide the decomposition:\n",
      "   - General prompts like \"Steps for XYZ.\\n1.\"\n",
      "   - Task-focused prompts like \"Write a story outline\" for narrative constructions.\n",
      "3. **Human Inputs**: Engaging human insight can also guide the decomposition process effectively.\n",
      "\n",
      "### Common Extensions of Task Decomposition Method\n",
      "\n",
      "1. **Tree of Thoughts (ToT)**:\n",
      "   - This extension, introduced by Yao et al. in 2023, enhances the CoT method by allowing exploration of multiple reasoning possibilities at each step.\n",
      "   - It organizes thoughts into a tree structure, where every problem is decomposed into multiple thought steps, allowing for branching paths and diverse problem-solving.\n",
      "   - This approach can utilize strategies like breadth-first search (BFS) or depth-first search (DFS) to evaluate different pathways through classifiers or voting mechanisms.\n",
      "\n",
      "These methodologies and extensions significantly improve the ability to address and manage complex tasks by breaking them into comprehensible parts.\n"
     ]
    }
   ],
   "source": [
    "# Define a new thread ID to track this conversation separately\n",
    "config = {\"configurable\": {\"thread_id\": \"def234\"}}\n",
    "\n",
    "# Multi-step user question that encourages iteration\n",
    "input_message = (\n",
    "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
    "    \"Once you get the answer, look up common extensions of that method.\"\n",
    ")\n",
    "\n",
    "# Stream each step of the agent's reasoning and actions\n",
    "for event in agent_executor.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},  # Input message\n",
    "    stream_mode=\"values\",  # Show messages only\n",
    "    config=config,  # Maintain history with unique thread ID\n",
    "):\n",
    "    # Print the last message at each stage of the agent's execution\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9bc0ba-12e9-41cd-b8d5-fc5f27787be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
