{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45077bad-b105-46a7-b260-2dc8ff9fc4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I import the necessary libraries to manage environment variables, interact with OpenAI, and connect to Milvus\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pymilvus import Collection, CollectionSchema, FieldSchema, DataType\n",
    "\n",
    "# I load the environment variables from my .env file where my API key is stored securely\n",
    "load_dotenv()\n",
    "\n",
    "# I initialize the OpenAI client using my API key so I can generate embeddings and use OpenAI services\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# From here, I’m ready to create embeddings with OpenAI and perform vector searches using Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc7661e4-f7e1-4e3e-8ff3-651331efa14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to Milvus established.\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import connections\n",
    "\n",
    "# I establish a connection to the Milvus server.\n",
    "# Replace \"localhost\" and 19530 with your Milvus server's actual host and port if different.\n",
    "connections.connect(\n",
    "    alias=\"default\",       # I give this connection an alias to reference it later\n",
    "    host=\"localhost\",      # The host where Milvus is running\n",
    "    port=\"19530\"           # The port Milvus listens on (default is 19530)\n",
    ")\n",
    "\n",
    "print(\"Connection to Milvus established.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4556189b-e5a7-45e6-9578-3f4a24f0738f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped existing collection 'appliance_reviews'.\n",
      "Created collection 'appliance_reviews' with the specified schema.\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import Collection, list_collections\n",
    "\n",
    "collection_name = \"appliance_reviews\"\n",
    "\n",
    "# Check if the collection already exists in Milvus\n",
    "if collection_name in list_collections():\n",
    "    # If it exists, drop it to avoid schema conflicts\n",
    "    existing_collection = Collection(collection_name)\n",
    "    existing_collection.drop()\n",
    "    print(f\"Dropped existing collection '{collection_name}'.\")\n",
    "\n",
    "# Define your schema fields here (replace with your actual schema)\n",
    "from pymilvus import FieldSchema, CollectionSchema, DataType\n",
    "\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=1536),\n",
    "    FieldSchema(name=\"combined_text\", dtype=DataType.VARCHAR, max_length=1024),\n",
    "    FieldSchema(name=\"unixReviewTime\", dtype=DataType.INT64)\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields=fields, description=\"Amazon appliance reviews with vectors and timestamps\")\n",
    "\n",
    "# Create the collection with the schema\n",
    "collection = Collection(name=collection_name, schema=schema)\n",
    "print(f\"Created collection '{collection_name}' with the specified schema.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65518bf9-0b8e-43d6-8124-f5ce9d1c10e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.66.5)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.7.1-cp312-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Downloading torch-2.7.1-cp312-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sympy, safetensors, torch, transformers, sentence-transformers\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed safetensors-0.5.3 sentence-transformers-4.1.0 sympy-1.14.0 torch-2.7.1 transformers-4.52.4\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "333a15d9-0fb4-42f9-89c9-7458f9aa6705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata shape: (11656, 9)\n",
      "Metadata columns: ['asin', 'price', 'imUrl', 'description', 'categories', 'title', 'brand', 'related', 'salesRank']\n",
      "Reviews shape: (143685, 9)\n",
      "Reviews columns: ['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText', 'overall', 'summary', 'unixReviewTime', 'reviewTime']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load JSON files into DataFrames\n",
    "metadata_path = '/Users/daniel/Documents/Northwestern/MSDS 420 - Database Systems/Final Project Implementation/Final_Project_Phase_1/Amazon/Amazon_Appliances_Metadata.json'\n",
    "reviews_path = '/Users/daniel/Documents/Northwestern/MSDS 420 - Database Systems/Final Project Implementation/Final_Project_Phase_1/Amazon/Amazon_Appliances_Reviews.json'\n",
    "\n",
    "metadata_df = pd.read_json(metadata_path, lines=True)\n",
    "reviews_df = pd.read_json(reviews_path, lines=True)\n",
    "\n",
    "# Print shape and columns for both DataFrames\n",
    "print(f\"Metadata shape: {metadata_df.shape}\")\n",
    "print(f\"Metadata columns: {metadata_df.columns.tolist()}\")\n",
    "print(f\"Reviews shape: {reviews_df.shape}\")\n",
    "print(f\"Reviews columns: {reviews_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bea2112-35a7-40e8-b0f2-7cda6320c80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         asin                                              title  price  \\\n",
      "0  0970408285                                                NaN  40.75   \n",
      "1  7301113188                                                NaN    NaN   \n",
      "2  B00002N7HY  Leviton 5050 50 Amp, 125/250 Volt, NEMA 10-50R...   2.29   \n",
      "\n",
      "                                       combined_text  \n",
      "0  Good fit Could have been longer though. well m...  \n",
      "1  I Love the Freezer storage line.. I like these...  \n",
      "2  expectations achieved. It works, no fires, etc...  \n"
     ]
    }
   ],
   "source": [
    "# Merge metadata and reviews on 'asin' to get product info alongside reviews\n",
    "merged_df = reviews_df.merge(metadata_df[['asin', 'title', 'price']], on='asin', how='left')\n",
    "\n",
    "# Create a combined text column from 'summary' and 'reviewText'\n",
    "merged_df['combined_text'] = (merged_df['summary'].fillna('') + ' ' + merged_df['reviewText'].fillna('')).str.strip()\n",
    "\n",
    "# Check the first 3 rows to verify\n",
    "print(merged_df[['asin', 'title', 'price', 'combined_text']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87cb08f0-b96c-487e-9a32-f7610450f173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings for 100 samples.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for the first 100 rows combined_text\n",
    "sample_texts = merged_df['combined_text'].head(100).tolist()\n",
    "embeddings = model.encode(sample_texts)\n",
    "\n",
    "print(f\"Generated embeddings for {len(embeddings)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3640e697-bfef-4442-b31a-9859fdd5bc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 100 embeddings, 100 texts, and 100 timestamps for insertion.\n"
     ]
    }
   ],
   "source": [
    "# Truncate combined_text to 1024 characters (Milvus VARCHAR limit)\n",
    "texts_to_insert = merged_df['combined_text'].head(100).apply(lambda x: x[:1024]).tolist()\n",
    "\n",
    "# Extract unixReviewTime for the first 100 rows\n",
    "timestamps_to_insert = merged_df['unixReviewTime'].head(100).tolist()\n",
    "\n",
    "# embeddings already generated, make sure to convert to list if not already\n",
    "embeddings_to_insert = embeddings.tolist()\n",
    "\n",
    "print(f\"Prepared {len(embeddings_to_insert)} embeddings, {len(texts_to_insert)} texts, and {len(timestamps_to_insert)} timestamps for insertion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7940b93-eb7b-468e-a4c8-30ce710d50b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Milvus server.\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import connections\n",
    "\n",
    "# Connect to Milvus server\n",
    "connections.connect(\n",
    "    alias=\"default\",  # connection alias\n",
    "    host=\"localhost\", # or your Milvus server host\n",
    "    port=\"19530\"      # default Milvus port\n",
    ")\n",
    "\n",
    "print(\"Connected to Milvus server.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcd05874-b765-4bae-92c0-30ea14b34e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection 'appliance_reviews' with 384-dimensional vectors.\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import connections, Collection, CollectionSchema, FieldSchema, DataType, list_collections\n",
    "\n",
    "# Connect first\n",
    "connections.connect(alias=\"default\", host=\"localhost\", port=\"19530\")\n",
    "\n",
    "collection_name = \"appliance_reviews\"\n",
    "\n",
    "# Drop collection if exists\n",
    "if collection_name in list_collections():\n",
    "    Collection(collection_name).drop()\n",
    "\n",
    "# Define schema with dim=384\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=384),\n",
    "    FieldSchema(name=\"combined_text\", dtype=DataType.VARCHAR, max_length=1024),\n",
    "    FieldSchema(name=\"unixReviewTime\", dtype=DataType.INT64),\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields, description=\"Amazon appliance reviews with 384-dim vectors\")\n",
    "\n",
    "# Create collection\n",
    "collection = Collection(name=collection_name, schema=schema)\n",
    "\n",
    "print(f\"Created collection '{collection_name}' with 384-dimensional vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f44e1d8d-f5a1-4737-94fe-d34aa15a4eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 100 embeddings, 100 texts, and 100 timestamps for insertion.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming merged_df is already loaded and has 'combined_text' and 'unixReviewTime'\n",
    "\n",
    "# Load the sentence transformer model (outputs 384-dim embeddings)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Select the first 100 samples (you can increase later)\n",
    "sample_df = merged_df.head(100)\n",
    "\n",
    "# Generate embeddings for combined_text column\n",
    "embeddings = model.encode(sample_df['combined_text'].tolist())\n",
    "\n",
    "# Truncate combined_text to 1024 characters for Milvus varchar field\n",
    "texts_to_insert = sample_df['combined_text'].apply(lambda x: x[:1024]).tolist()\n",
    "\n",
    "# Extract unixReviewTime as list\n",
    "timestamps_to_insert = sample_df['unixReviewTime'].tolist()\n",
    "\n",
    "# Convert embeddings to list of lists if not already\n",
    "embeddings_to_insert = embeddings.tolist()\n",
    "\n",
    "print(f\"Prepared {len(embeddings_to_insert)} embeddings, {len(texts_to_insert)} texts, and {len(timestamps_to_insert)} timestamps for insertion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efaae43d-165e-4233-84cc-23bcc29c8815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 100 records into Milvus.\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import connections, Collection\n",
    "\n",
    "# Connect to Milvus server (if not already connected)\n",
    "connections.connect(\n",
    "    alias=\"default\",\n",
    "    host=\"localhost\",\n",
    "    port=\"19530\"\n",
    ")\n",
    "\n",
    "# Load the collection (make sure schema dimension is 384)\n",
    "collection = Collection(\"appliance_reviews\")\n",
    "\n",
    "# Insert the data - order must match schema fields: embedding, combined_text, unixReviewTime\n",
    "collection.insert([\n",
    "    embeddings_to_insert,\n",
    "    texts_to_insert,\n",
    "    timestamps_to_insert\n",
    "])\n",
    "\n",
    "print(f\"Inserted {len(texts_to_insert)} records into Milvus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b372bd30-c748-4c4a-b521-59e72cbdc783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement 1 - Combined Queries for Group C:\n",
      "                                               Query\n",
      "0  Get a list of those reviews that are similar t...\n",
      "1  Get a list of those reviews that are similar t...\n",
      "2  Get a list of those reviews that are similar t...\n",
      "3  Find reviews semantically similar to: 'Looks g...\n",
      "4  Retrieve reviews similar to: 'Powerful motor a...\n",
      "5  Get reviews expressing frustration with delaye...\n"
     ]
    }
   ],
   "source": [
    "# Requirement 1:\n",
    "# Create a table of queries for the selected group (Group C in this example)\n",
    "# including 3 custom queries I created in Phase 1 that fit the same group.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Queries from Group C (Hybrid Search Queries) as per Final Project doc\n",
    "group_c_queries = [\n",
    "    \"Get a list of those reviews that are similar to this text: 'It could so nearly have been a great fridge, but it's the design that brings it down. The doors are clunky, and the buttons on the outside are unappealing and cheap looking.'\",\n",
    "    \"Get a list of those reviews that are similar to this text and got reviewed in February of 2013.\",\n",
    "    \"Get a list of those reviews that are similar to this text: 'This microwave started to make a lot of noise after using it for only few days' and got reviewed in February of 2013.\"\n",
    "]\n",
    "\n",
    "# My 3 custom queries from Phase 1 for Group C\n",
    "custom_queries = [\n",
    "    \"Find reviews semantically similar to: 'Looks great but doesn’t last long.'\",\n",
    "    \"Retrieve reviews similar to: 'Powerful motor and easy to clean' for products under the 'Blender' category.\",\n",
    "    \"Get reviews expressing frustration with delayed shipping or broken packaging, even if those exact words aren’t used.\"\n",
    "]\n",
    "\n",
    "# Combine all queries into a DataFrame\n",
    "queries_df = pd.DataFrame({\n",
    "    \"Query\": group_c_queries + custom_queries\n",
    "})\n",
    "\n",
    "print(\"Requirement 1 - Combined Queries for Group C:\")\n",
    "print(queries_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb9feace-7369-4d18-a0ca-f2b297c62637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Database: Milvus\n",
      "Benchmarking Metrics:\n",
      "- Similarity Search Performance\n",
      "- Indexing Efficiency\n",
      "- Storage Efficiency\n"
     ]
    }
   ],
   "source": [
    "# Requirement 2 - Database Selection and Benchmarking Metrics\n",
    "\n",
    "# For the queries listed in Requirement 1 (Group C - Hybrid Search Queries),\n",
    "# I have selected Milvus as the database system because it excels at handling\n",
    "# similarity and semantic searches with vector embeddings.\n",
    "\n",
    "# Benchmarking Metrics for Milvus (Vector Database):\n",
    "# 1. Similarity Search Performance - How quickly and accurately the database\n",
    "#    finds vectors close to a query vector.\n",
    "# 2. Indexing Efficiency - Speed and resource usage to create and maintain\n",
    "#    vector indexes.\n",
    "# 3. Storage Efficiency - How well the database compresses and stores high-\n",
    "#    dimensional vector data for scalability.\n",
    "\n",
    "selected_database = \"Milvus\"\n",
    "\n",
    "benchmark_metrics = [\n",
    "    \"Similarity Search Performance\",\n",
    "    \"Indexing Efficiency\",\n",
    "    \"Storage Efficiency\"\n",
    "]\n",
    "\n",
    "print(\"Selected Database:\", selected_database)\n",
    "print(\"Benchmarking Metrics:\")\n",
    "for metric in benchmark_metrics:\n",
    "    print(f\"- {metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c500e8e9-0a71-45d2-90d2-4f8e8505b293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Milvus\n",
      "Loaded existing collection 'appliance_reviews'\n",
      "Inserted 100 records into Milvus.\n",
      "Collection loaded and ready for queries.\n"
     ]
    }
   ],
   "source": [
    "# Requirement 3 - Design and develop a Milvus database application\n",
    "# I connected to Milvus, created a collection schema; if it doesn't exist, I'll create it,\n",
    "# I prepared the data by merging reviews and metadata, generate embeddings,\n",
    "# insert the data into Milvus, create an index on the vector field,\n",
    "# and load the collection for queries.\n",
    "\n",
    "from pymilvus import connections, Collection, list_collections, FieldSchema, CollectionSchema, DataType\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Step 1: Connect to the Milvus server\n",
    "connections.connect(alias=\"default\", host=\"localhost\", port=\"19530\")\n",
    "print(\"Connected to Milvus\")\n",
    "\n",
    "# Step 2: Define the collection schema with vector dimension 384 (matching embeddings)\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=384),\n",
    "    FieldSchema(name=\"combined_text\", dtype=DataType.VARCHAR, max_length=1024),\n",
    "    FieldSchema(name=\"unixReviewTime\", dtype=DataType.INT64),\n",
    "]\n",
    "schema = CollectionSchema(fields, description=\"Amazon appliance reviews with embeddings\")\n",
    "\n",
    "# Step 3: Create or load the collection\n",
    "collection_name = \"appliance_reviews\"\n",
    "if collection_name in list_collections():\n",
    "    collection = Collection(collection_name)\n",
    "    print(f\"Loaded existing collection '{collection_name}'\")\n",
    "else:\n",
    "    collection = Collection(name=collection_name, schema=schema)\n",
    "    print(f\"Created new collection '{collection_name}'\")\n",
    "\n",
    "# Step 4: Prepare the data\n",
    "# Ensure metadata_df and reviews_df are already loaded\n",
    "merged_df = reviews_df.merge(metadata_df[['asin', 'title', 'price']], on='asin', how='left')\n",
    "merged_df['combined_text'] = (merged_df['summary'].fillna('') + ' ' + merged_df['reviewText'].fillna('')).str.strip()\n",
    "\n",
    "# Step 5: Load embedding model and generate embeddings for first 100 rows\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sample_df = merged_df.head(100).copy()\n",
    "sample_df['embedding'] = sample_df['combined_text'].apply(lambda x: model.encode(x).tolist())\n",
    "\n",
    "# Step 6: Prepare lists for insertion (truncate text and extract timestamps)\n",
    "texts_to_insert = sample_df['combined_text'].apply(lambda x: x[:1024]).tolist()\n",
    "embeddings_to_insert = sample_df['embedding'].tolist()\n",
    "timestamps_to_insert = sample_df['unixReviewTime'].tolist()\n",
    "\n",
    "# Step 7: Insert the data into the Milvus collection\n",
    "collection.insert([embeddings_to_insert, texts_to_insert, timestamps_to_insert])\n",
    "print(f\"Inserted {len(texts_to_insert)} records into Milvus.\")\n",
    "\n",
    "# Step 8: Create index on the vector field if it doesn't exist\n",
    "if not collection.indexes:\n",
    "    index_params = {\n",
    "        \"metric_type\": \"IP\",  # Inner Product similarity metric\n",
    "        \"index_type\": \"HNSW\",\n",
    "        \"params\": {\"M\": 8, \"efConstruction\": 64}\n",
    "    }\n",
    "    collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "    print(\"Index created on 'embedding' field.\")\n",
    "\n",
    "# Step 9: Load collection into memory to prepare for search queries\n",
    "collection.load()\n",
    "print(\"Collection loaded and ready for queries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c33614b7-8a95-4969-863e-57d277569987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for query: 'This microwave started to make a lot of noise after only a few days'\n",
      "\n",
      "Score: 0.2741\n",
      "Review Text: Five Stars Perfect length to connect my over the range microwave to a wall plug.\n",
      "Review Time (unix): 1404345600\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.2741\n",
      "Review Text: Five Stars Perfect length to connect my over the range microwave to a wall plug.\n",
      "Review Time (unix): 1404345600\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.2741\n",
      "Review Text: Five Stars Perfect length to connect my over the range microwave to a wall plug.\n",
      "Review Time (unix): 1404345600\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.2212\n",
      "Review Text: Great product Not too much to say about this. It works great. We use it in our garage to plug in our stereo when we workout. We use it nearly everyday and haven't had any issues.  It works without fail.\n",
      "Review Time (unix): 1354924800\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.2212\n",
      "Review Text: Great product Not too much to say about this. It works great. We use it in our garage to plug in our stereo when we workout. We use it nearly everyday and haven't had any issues.  It works without fail.\n",
      "Review Time (unix): 1354924800\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Sample query text to search similar reviews\n",
    "query_text = \"This microwave started to make a lot of noise after only a few days\"\n",
    "\n",
    "# Encode the query text using the same embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "query_embedding = model.encode([query_text]).tolist()\n",
    "\n",
    "# Load the collection again to be safe\n",
    "collection = Collection(\"appliance_reviews\")\n",
    "\n",
    "# Ensure the collection is loaded before searching\n",
    "collection.load()\n",
    "\n",
    "# Perform similarity search - get top 5 similar reviews\n",
    "results = collection.search(\n",
    "    data=query_embedding,\n",
    "    anns_field=\"embedding\",\n",
    "    param={\"metric_type\": \"IP\", \"params\": {\"nprobe\": 10}},\n",
    "    limit=5,\n",
    "    output_fields=[\"combined_text\", \"unixReviewTime\"]\n",
    ")\n",
    "\n",
    "# Print the results with similarity scores\n",
    "print(f\"Search results for query: '{query_text}'\\n\")\n",
    "for hit in results[0]:\n",
    "    print(f\"Score: {hit.score:.4f}\")\n",
    "    print(f\"Review Text: {hit.entity.get('combined_text')}\")\n",
    "    print(f\"Review Time (unix): {hit.entity.get('unixReviewTime')}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d28cd1a-4d92-4ce7-9737-6b07e0e78f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows to embed and insert: 143685\n",
      "Inserted records from 0 to 499\n",
      "Inserted records from 500 to 999\n",
      "Inserted records from 1000 to 1499\n",
      "Inserted records from 1500 to 1999\n",
      "Inserted records from 2000 to 2499\n",
      "Inserted records from 2500 to 2999\n",
      "Inserted records from 3000 to 3499\n",
      "Inserted records from 3500 to 3999\n",
      "Inserted records from 4000 to 4499\n",
      "Inserted records from 4500 to 4999\n",
      "Inserted records from 5000 to 5499\n",
      "Inserted records from 5500 to 5999\n",
      "Inserted records from 6000 to 6499\n",
      "Inserted records from 6500 to 6999\n",
      "Inserted records from 7000 to 7499\n",
      "Inserted records from 7500 to 7999\n",
      "Inserted records from 8000 to 8499\n",
      "Inserted records from 8500 to 8999\n",
      "Inserted records from 9000 to 9499\n",
      "Inserted records from 9500 to 9999\n",
      "Inserted records from 10000 to 10499\n",
      "Inserted records from 10500 to 10999\n",
      "Inserted records from 11000 to 11499\n",
      "Inserted records from 11500 to 11999\n",
      "Inserted records from 12000 to 12499\n",
      "Inserted records from 12500 to 12999\n",
      "Inserted records from 13000 to 13499\n",
      "Inserted records from 13500 to 13999\n",
      "Inserted records from 14000 to 14499\n",
      "Inserted records from 14500 to 14999\n",
      "Inserted records from 15000 to 15499\n",
      "Inserted records from 15500 to 15999\n",
      "Inserted records from 16000 to 16499\n",
      "Inserted records from 16500 to 16999\n",
      "Inserted records from 17000 to 17499\n",
      "Inserted records from 17500 to 17999\n",
      "Inserted records from 18000 to 18499\n",
      "Inserted records from 18500 to 18999\n",
      "Inserted records from 19000 to 19499\n",
      "Inserted records from 19500 to 19999\n",
      "Inserted records from 20000 to 20499\n",
      "Inserted records from 20500 to 20999\n",
      "Inserted records from 21000 to 21499\n",
      "Inserted records from 21500 to 21999\n",
      "Inserted records from 22000 to 22499\n",
      "Inserted records from 22500 to 22999\n",
      "Inserted records from 23000 to 23499\n",
      "Inserted records from 23500 to 23999\n",
      "Inserted records from 24000 to 24499\n",
      "Inserted records from 24500 to 24999\n",
      "Inserted records from 25000 to 25499\n",
      "Inserted records from 25500 to 25999\n",
      "Inserted records from 26000 to 26499\n",
      "Inserted records from 26500 to 26999\n",
      "Inserted records from 27000 to 27499\n",
      "Inserted records from 27500 to 27999\n",
      "Inserted records from 28000 to 28499\n",
      "Inserted records from 28500 to 28999\n",
      "Inserted records from 29000 to 29499\n",
      "Inserted records from 29500 to 29999\n",
      "Inserted records from 30000 to 30499\n",
      "Inserted records from 30500 to 30999\n",
      "Inserted records from 31000 to 31499\n",
      "Inserted records from 31500 to 31999\n",
      "Inserted records from 32000 to 32499\n",
      "Inserted records from 32500 to 32999\n",
      "Inserted records from 33000 to 33499\n",
      "Inserted records from 33500 to 33999\n",
      "Inserted records from 34000 to 34499\n",
      "Inserted records from 34500 to 34999\n",
      "Inserted records from 35000 to 35499\n",
      "Inserted records from 35500 to 35999\n",
      "Inserted records from 36000 to 36499\n",
      "Inserted records from 36500 to 36999\n",
      "Inserted records from 37000 to 37499\n",
      "Inserted records from 37500 to 37999\n",
      "Inserted records from 38000 to 38499\n",
      "Inserted records from 38500 to 38999\n",
      "Inserted records from 39000 to 39499\n",
      "Inserted records from 39500 to 39999\n",
      "Inserted records from 40000 to 40499\n",
      "Inserted records from 40500 to 40999\n",
      "Inserted records from 41000 to 41499\n",
      "Inserted records from 41500 to 41999\n",
      "Inserted records from 42000 to 42499\n",
      "Inserted records from 42500 to 42999\n",
      "Inserted records from 43000 to 43499\n",
      "Inserted records from 43500 to 43999\n",
      "Inserted records from 44000 to 44499\n",
      "Inserted records from 44500 to 44999\n",
      "Inserted records from 45000 to 45499\n",
      "Inserted records from 45500 to 45999\n",
      "Inserted records from 46000 to 46499\n",
      "Inserted records from 46500 to 46999\n",
      "Inserted records from 47000 to 47499\n",
      "Inserted records from 47500 to 47999\n",
      "Inserted records from 48000 to 48499\n",
      "Inserted records from 48500 to 48999\n",
      "Inserted records from 49000 to 49499\n",
      "Inserted records from 49500 to 49999\n",
      "Inserted records from 50000 to 50499\n",
      "Inserted records from 50500 to 50999\n",
      "Inserted records from 51000 to 51499\n",
      "Inserted records from 51500 to 51999\n",
      "Inserted records from 52000 to 52499\n",
      "Inserted records from 52500 to 52999\n",
      "Inserted records from 53000 to 53499\n",
      "Inserted records from 53500 to 53999\n",
      "Inserted records from 54000 to 54499\n",
      "Inserted records from 54500 to 54999\n",
      "Inserted records from 55000 to 55499\n",
      "Inserted records from 55500 to 55999\n",
      "Inserted records from 56000 to 56499\n",
      "Inserted records from 56500 to 56999\n",
      "Inserted records from 57000 to 57499\n",
      "Inserted records from 57500 to 57999\n",
      "Inserted records from 58000 to 58499\n",
      "Inserted records from 58500 to 58999\n",
      "Inserted records from 59000 to 59499\n",
      "Inserted records from 59500 to 59999\n",
      "Inserted records from 60000 to 60499\n",
      "Inserted records from 60500 to 60999\n",
      "Inserted records from 61000 to 61499\n",
      "Inserted records from 61500 to 61999\n",
      "Inserted records from 62000 to 62499\n",
      "Inserted records from 62500 to 62999\n",
      "Inserted records from 63000 to 63499\n",
      "Inserted records from 63500 to 63999\n",
      "Inserted records from 64000 to 64499\n",
      "Inserted records from 64500 to 64999\n",
      "Inserted records from 65000 to 65499\n",
      "Inserted records from 65500 to 65999\n",
      "Inserted records from 66000 to 66499\n",
      "Inserted records from 66500 to 66999\n",
      "Inserted records from 67000 to 67499\n",
      "Inserted records from 67500 to 67999\n",
      "Inserted records from 68000 to 68499\n",
      "Inserted records from 68500 to 68999\n",
      "Inserted records from 69000 to 69499\n",
      "Inserted records from 69500 to 69999\n",
      "Inserted records from 70000 to 70499\n",
      "Inserted records from 70500 to 70999\n",
      "Inserted records from 71000 to 71499\n",
      "Inserted records from 71500 to 71999\n",
      "Inserted records from 72000 to 72499\n",
      "Inserted records from 72500 to 72999\n",
      "Inserted records from 73000 to 73499\n",
      "Inserted records from 73500 to 73999\n",
      "Inserted records from 74000 to 74499\n",
      "Inserted records from 74500 to 74999\n",
      "Inserted records from 75000 to 75499\n",
      "Inserted records from 75500 to 75999\n",
      "Inserted records from 76000 to 76499\n",
      "Inserted records from 76500 to 76999\n",
      "Inserted records from 77000 to 77499\n",
      "Inserted records from 77500 to 77999\n",
      "Inserted records from 78000 to 78499\n",
      "Inserted records from 78500 to 78999\n",
      "Inserted records from 79000 to 79499\n",
      "Inserted records from 79500 to 79999\n",
      "Inserted records from 80000 to 80499\n",
      "Inserted records from 80500 to 80999\n",
      "Inserted records from 81000 to 81499\n",
      "Inserted records from 81500 to 81999\n",
      "Inserted records from 82000 to 82499\n",
      "Inserted records from 82500 to 82999\n",
      "Inserted records from 83000 to 83499\n",
      "Inserted records from 83500 to 83999\n",
      "Inserted records from 84000 to 84499\n",
      "Inserted records from 84500 to 84999\n",
      "Inserted records from 85000 to 85499\n",
      "Inserted records from 85500 to 85999\n",
      "Inserted records from 86000 to 86499\n",
      "Inserted records from 86500 to 86999\n",
      "Inserted records from 87000 to 87499\n",
      "Inserted records from 87500 to 87999\n",
      "Inserted records from 88000 to 88499\n",
      "Inserted records from 88500 to 88999\n",
      "Inserted records from 89000 to 89499\n",
      "Inserted records from 89500 to 89999\n",
      "Inserted records from 90000 to 90499\n",
      "Inserted records from 90500 to 90999\n",
      "Inserted records from 91000 to 91499\n",
      "Inserted records from 91500 to 91999\n",
      "Inserted records from 92000 to 92499\n",
      "Inserted records from 92500 to 92999\n",
      "Inserted records from 93000 to 93499\n",
      "Inserted records from 93500 to 93999\n",
      "Inserted records from 94000 to 94499\n",
      "Inserted records from 94500 to 94999\n",
      "Inserted records from 95000 to 95499\n",
      "Inserted records from 95500 to 95999\n",
      "Inserted records from 96000 to 96499\n",
      "Inserted records from 96500 to 96999\n",
      "Inserted records from 97000 to 97499\n",
      "Inserted records from 97500 to 97999\n",
      "Inserted records from 98000 to 98499\n",
      "Inserted records from 98500 to 98999\n",
      "Inserted records from 99000 to 99499\n",
      "Inserted records from 99500 to 99999\n",
      "Inserted records from 100000 to 100499\n",
      "Inserted records from 100500 to 100999\n",
      "Inserted records from 101000 to 101499\n",
      "Inserted records from 101500 to 101999\n",
      "Inserted records from 102000 to 102499\n",
      "Inserted records from 102500 to 102999\n",
      "Inserted records from 103000 to 103499\n",
      "Inserted records from 103500 to 103999\n",
      "Inserted records from 104000 to 104499\n",
      "Inserted records from 104500 to 104999\n",
      "Inserted records from 105000 to 105499\n",
      "Inserted records from 105500 to 105999\n",
      "Inserted records from 106000 to 106499\n",
      "Inserted records from 106500 to 106999\n",
      "Inserted records from 107000 to 107499\n",
      "Inserted records from 107500 to 107999\n",
      "Inserted records from 108000 to 108499\n",
      "Inserted records from 108500 to 108999\n",
      "Inserted records from 109000 to 109499\n",
      "Inserted records from 109500 to 109999\n",
      "Inserted records from 110000 to 110499\n",
      "Inserted records from 110500 to 110999\n",
      "Inserted records from 111000 to 111499\n",
      "Inserted records from 111500 to 111999\n",
      "Inserted records from 112000 to 112499\n",
      "Inserted records from 112500 to 112999\n",
      "Inserted records from 113000 to 113499\n",
      "Inserted records from 113500 to 113999\n",
      "Inserted records from 114000 to 114499\n",
      "Inserted records from 114500 to 114999\n",
      "Inserted records from 115000 to 115499\n",
      "Inserted records from 115500 to 115999\n",
      "Inserted records from 116000 to 116499\n",
      "Inserted records from 116500 to 116999\n",
      "Inserted records from 117000 to 117499\n",
      "Inserted records from 117500 to 117999\n",
      "Inserted records from 118000 to 118499\n",
      "Inserted records from 118500 to 118999\n",
      "Inserted records from 119000 to 119499\n",
      "Inserted records from 119500 to 119999\n",
      "Inserted records from 120000 to 120499\n",
      "Inserted records from 120500 to 120999\n",
      "Inserted records from 121000 to 121499\n",
      "Inserted records from 121500 to 121999\n",
      "Inserted records from 122000 to 122499\n",
      "Inserted records from 122500 to 122999\n",
      "Inserted records from 123000 to 123499\n",
      "Inserted records from 123500 to 123999\n",
      "Inserted records from 124000 to 124499\n",
      "Inserted records from 124500 to 124999\n",
      "Inserted records from 125000 to 125499\n",
      "Inserted records from 125500 to 125999\n",
      "Inserted records from 126000 to 126499\n",
      "Inserted records from 126500 to 126999\n",
      "Inserted records from 127000 to 127499\n",
      "Inserted records from 127500 to 127999\n",
      "Inserted records from 128000 to 128499\n",
      "Inserted records from 128500 to 128999\n",
      "Inserted records from 129000 to 129499\n",
      "Inserted records from 129500 to 129999\n",
      "Inserted records from 130000 to 130499\n",
      "Inserted records from 130500 to 130999\n",
      "Inserted records from 131000 to 131499\n",
      "Inserted records from 131500 to 131999\n",
      "Inserted records from 132000 to 132499\n",
      "Inserted records from 132500 to 132999\n",
      "Inserted records from 133000 to 133499\n",
      "Inserted records from 133500 to 133999\n",
      "Inserted records from 134000 to 134499\n",
      "Inserted records from 134500 to 134999\n",
      "Inserted records from 135000 to 135499\n",
      "Inserted records from 135500 to 135999\n",
      "Inserted records from 136000 to 136499\n",
      "Inserted records from 136500 to 136999\n",
      "Inserted records from 137000 to 137499\n",
      "Inserted records from 137500 to 137999\n",
      "Inserted records from 138000 to 138499\n",
      "Inserted records from 138500 to 138999\n",
      "Inserted records from 139000 to 139499\n",
      "Inserted records from 139500 to 139999\n",
      "Inserted records from 140000 to 140499\n",
      "Inserted records from 140500 to 140999\n",
      "Inserted records from 141000 to 141499\n",
      "Inserted records from 141500 to 141999\n",
      "Inserted records from 142000 to 142499\n",
      "Inserted records from 142500 to 142999\n",
      "Inserted records from 143000 to 143499\n",
      "Inserted records from 143500 to 143684\n",
      "Finished inserting all records.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "batch_size = 500  # adjust as needed\n",
    "total_rows = len(merged_df)\n",
    "print(f\"Total rows to embed and insert: {total_rows}\")\n",
    "\n",
    "for start_idx in range(0, total_rows, batch_size):\n",
    "    end_idx = min(start_idx + batch_size, total_rows)\n",
    "    batch_df = merged_df.iloc[start_idx:end_idx].copy()\n",
    "    \n",
    "    # Generate embeddings for this batch\n",
    "    batch_df['embedding'] = batch_df['combined_text'].apply(lambda x: model.encode(x).tolist())\n",
    "    \n",
    "    # Prepare insertion data\n",
    "    embeddings_batch = batch_df['embedding'].tolist()\n",
    "    texts_batch = batch_df['combined_text'].apply(lambda x: x[:1024]).tolist()\n",
    "    timestamps_batch = batch_df['unixReviewTime'].tolist()\n",
    "    \n",
    "    # Insert batch into Milvus\n",
    "    collection.insert([embeddings_batch, texts_batch, timestamps_batch])\n",
    "    print(f\"Inserted records from {start_idx} to {end_idx-1}\")\n",
    "\n",
    "print(\"Finished inserting all records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd5ded0e-bd38-4033-8fd8-d45d1b6ce6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for query: 'This microwave started to make a lot of noise after only a few days'\n",
      "\n",
      "Score: 0.6578\n",
      "Review Text: common microwave problem I'm glad I bought 2. After installing the first one, which worked for a couple  of days another one went bad. It only takes 5 minutes to install, so it's no big deal. My 11 year old microwave is working great again.\n",
      "Review Time (unix): 1398556800\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6386\n",
      "Review Text: Bought ours at Lowes My microwave has the same problems as the other reviews.  Just got off the phone with the service center.  Whew!  Glad we got the extended warranty.  Will update after service in a couple of days.\n",
      "Review Time (unix): 1402272000\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6255\n",
      "Review Text: Replacement works great. noise issue resolved. a lot easier than replacing the microwave. It took a little effort to get in to change the motor.\n",
      "Review Time (unix): 1366761600\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6175\n",
      "Review Text: Worked Microwave was sparking and fiance wanted to buy a new one.  I asked for the chance to fix our existing one and came out a champ.\n",
      "Review Time (unix): 1391817600\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6158\n",
      "Review Text: Repair broken microwave My GE microwave quit working and I suspected the Magnetron was the culprit so ordered this and it fixed the problem.\n",
      "Review Time (unix): 1397001600\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Sample query text to search similar reviews\n",
    "query_text = \"This microwave started to make a lot of noise after only a few days\"\n",
    "\n",
    "# Encode the query text using the same embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "query_embedding = model.encode([query_text]).tolist()\n",
    "\n",
    "# Load the collection again to be safe\n",
    "collection = Collection(\"appliance_reviews\")\n",
    "\n",
    "# Ensure the collection is loaded before searching\n",
    "collection.load()\n",
    "\n",
    "# Perform similarity search - get top 5 similar reviews\n",
    "results = collection.search(\n",
    "    data=query_embedding,\n",
    "    anns_field=\"embedding\",\n",
    "    param={\"metric_type\": \"IP\", \"params\": {\"nprobe\": 10}},\n",
    "    limit=5,\n",
    "    output_fields=[\"combined_text\", \"unixReviewTime\"]\n",
    ")\n",
    "\n",
    "# Print the results with similarity scores\n",
    "print(f\"Search results for query: '{query_text}'\\n\")\n",
    "for hit in results[0]:\n",
    "    print(f\"Score: {hit.score:.4f}\")\n",
    "    print(f\"Review Text: {hit.entity.get('combined_text')}\")\n",
    "    print(f\"Review Time (unix): {hit.entity.get('unixReviewTime')}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a6cc275f-44b5-40db-bc1f-dda130a91ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: It could so nearly have been a great fridge, but it's the design that brings it down.\n",
      "Score: 0.7131, Review: Had this fridge for a couple years now and Love it. I love it. Not a single issue. Everything is gre..., Time: 1397606400\n",
      "Score: 0.7120, Review: Nice design, poor quality This is a very well designed and well thought out refrigerator. Without qu..., Time: 1350777600\n",
      "Score: 0.7086, Review: ELEGANT AND PRACTICAL This refrigerator is really slick looking, and that's just the beginning. It's..., Time: 1362268800\n",
      "Score: 0.7056, Review: Great Fridge! The fridge was exactly what we were looking for and arrived in a timely fashion..., Time: 1280102400\n",
      "Score: 0.7055, Review: Great fridge I had upgraded from a fridge with the freezer on top and refrigerator on the bottom.  W..., Time: 1389139200\n",
      "------------------------------------------------------------\n",
      "Query: This microwave started to make a lot of noise after using it for only few days\n",
      "Score: 0.6569, Review: common microwave problem I'm glad I bought 2. After installing the first one, which worked for a cou..., Time: 1398556800\n",
      "Score: 0.6383, Review: Replacement works great. noise issue resolved. a lot easier than replacing the microwave. It took a ..., Time: 1366761600\n",
      "Score: 0.6353, Review: Bought ours at Lowes My microwave has the same problems as the other reviews.  Just got off the phon..., Time: 1402272000\n",
      "Score: 0.6333, Review: too loud! microwave stays running to cool forever Nice combination oven/microwave. Has convection fu..., Time: 1337126400\n",
      "Score: 0.6270, Review: Worked Microwave was sparking and fiance wanted to buy a new one.  I asked for the chance to fix our..., Time: 1391817600\n",
      "------------------------------------------------------------\n",
      "Query: Powerful motor and easy to clean blender\n",
      "Score: 0.6316, Review: Very good machine This purchase was great for me, very efficient and clean. One of my best investmen..., Time: 1142121600\n",
      "Score: 0.6192, Review: Beautiful & Efficient..LOVE IT!!!! Bought this in October and love it!!!!! Does not look cheap and m..., Time: 1385251200\n",
      "Score: 0.6015, Review: couldn't be better Was in dire need of this motor.  It came fast, and fit perfectly.  Needed an elec..., Time: 1357257600\n",
      "Score: 0.5998, Review: Satisfied Customer Very happy with my Waste King garbage disposal purchase.  The 1/2 HP motor is ver..., Time: 1379462400\n",
      "Score: 0.5961, Review: Impressive power and quietness. Excellent disposer. My plumber reccomended a 3/4 horsepower motor or..., Time: 1386633600\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Requirement 4 - Create code for semantic similarity search queries using Milvus\n",
    "# In this code, I embed natural language query texts using the same SentenceTransformer model\n",
    "# that I used to generate review embeddings. Then, I perform a similarity search on the Milvus\n",
    "# collection to retrieve the most relevant reviews based on their vector embeddings.\n",
    "# Finally, I format and display the results including similarity scores, review texts, and timestamps.\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pymilvus import Collection\n",
    "\n",
    "# Initialize the embedding model once to use for all queries\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Load the Milvus collection and ensure it's loaded for search\n",
    "collection = Collection(\"appliance_reviews\")\n",
    "collection.load()\n",
    "\n",
    "def search_similar_reviews(query_text, top_k=5):\n",
    "    # Embed the input query text to get its vector representation\n",
    "    query_embedding = model.encode([query_text]).tolist()\n",
    "\n",
    "    # Perform similarity search in Milvus with the query embedding vector\n",
    "    results = collection.search(\n",
    "        data=query_embedding,\n",
    "        anns_field=\"embedding\",\n",
    "        param={\"metric_type\": \"IP\", \"params\": {\"nprobe\": 10}},  # Inner product metric for similarity\n",
    "        limit=top_k,\n",
    "        output_fields=[\"combined_text\", \"unixReviewTime\"]  # Retrieve review text and review timestamp\n",
    "    )\n",
    "\n",
    "    # Process and format the search results\n",
    "    matches = []\n",
    "    for hit in results[0]:\n",
    "        matches.append({\n",
    "            \"score\": hit.score,\n",
    "            \"review_text\": hit.entity.get(\"combined_text\"),\n",
    "            \"review_time\": hit.entity.get(\"unixReviewTime\")\n",
    "        })\n",
    "    return matches\n",
    "\n",
    "# Example Group C queries from the requirements to test the search function\n",
    "queries = [\n",
    "    \"It could so nearly have been a great fridge, but it's the design that brings it down.\",\n",
    "    \"This microwave started to make a lot of noise after using it for only few days\",\n",
    "    \"Powerful motor and easy to clean blender\"\n",
    "]\n",
    "\n",
    "# Loop through each query, run the search, and print the top results\n",
    "for q in queries:\n",
    "    print(f\"Query: {q}\")\n",
    "    results = search_similar_reviews(q)\n",
    "    for res in results:\n",
    "        print(f\"Score: {res['score']:.4f}, Review: {res['review_text'][:100]}..., Time: {res['review_time']}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad3d24be-46fd-4f6a-a0b6-3780a896bd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for query: 'It could so nearly have been a great fridge, but it's the design that brings it down.'\n",
      "\n",
      "Score: 0.7131\n",
      "Review Text: Had this fridge for a couple years now and Love it. I love it. Not a single issue. Everything is great . Design particularly. Everyone comments about what a nice fridge. I am a proud owner.\n",
      "Review Time (unix): 1397606400\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.7120\n",
      "Review Text: Nice design, poor quality This is a very well designed and well thought out refrigerator. Without question, the nicest fridge I've ever owned.... with one problem. This unit was shipped from the factory with a non-functioning ice maker. After a month of trying to get it fixed, we're shipping it back to Mexico tomorrow. There's really no excuse for a company with a reputation like Electrolux to ship products that don't work. Too bad - we really like the design. But we'll be looking elsewhere now.\n",
      "Review Time (unix): 1350777600\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.7086\n",
      "Review Text: ELEGANT AND PRACTICAL This refrigerator is really slick looking, and that's just the beginning. It's roomy for a relatively small fridge, with an excellent layout. Love the freezer on the bottom with three pullouts, and the counter depth, which ensures things don't get lost in the back. It was not more expensive than the average fridge these days, but the look is so different. Instead of those overblown, puffy, textured plastic semi-cheesy common fridges, this has clean lines, brushed stainless, energy efficiency, and a utilitarian understated elegance. We've had it for about a month and so far, no complaints. I'm so glad we opted for this one. Far and away a superior appliance.\n",
      "Review Time (unix): 1362268800\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.7056\n",
      "Review Text: Great Fridge! The fridge was exactly what we were looking for and arrived in a timely fashion\n",
      "Review Time (unix): 1280102400\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.7055\n",
      "Review Text: Great fridge I had upgraded from a fridge with the freezer on top and refrigerator on the bottom.  We needed a new one so we can put the old one in the garage to store drinks.Its a great looking fridge with the doors that are curved outward and on the top.  The icemaker quickly mades 10 pounds of ice cubes within 2 days of plugging it in.  It has a built in water filter so the water and ice are great tasting.It takes getting used to from having a top/bottom to side by side. My youngest love it that she can get ice cream from the lower level of the freezer section.Looks like there aren't very many reviews on this model. Wonder if its a brand new design.\n",
      "Review Time (unix): 1389139200\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Search results for query: 'This microwave started to make a lot of noise after only a few days'\n",
      "\n",
      "Score: 0.6578\n",
      "Review Text: common microwave problem I'm glad I bought 2. After installing the first one, which worked for a couple  of days another one went bad. It only takes 5 minutes to install, so it's no big deal. My 11 year old microwave is working great again.\n",
      "Review Time (unix): 1398556800\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6386\n",
      "Review Text: Bought ours at Lowes My microwave has the same problems as the other reviews.  Just got off the phone with the service center.  Whew!  Glad we got the extended warranty.  Will update after service in a couple of days.\n",
      "Review Time (unix): 1402272000\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6255\n",
      "Review Text: Replacement works great. noise issue resolved. a lot easier than replacing the microwave. It took a little effort to get in to change the motor.\n",
      "Review Time (unix): 1366761600\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6175\n",
      "Review Text: Worked Microwave was sparking and fiance wanted to buy a new one.  I asked for the chance to fix our existing one and came out a champ.\n",
      "Review Time (unix): 1391817600\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6158\n",
      "Review Text: Repair broken microwave My GE microwave quit working and I suspected the Magnetron was the culprit so ordered this and it fixed the problem.\n",
      "Review Time (unix): 1397001600\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Search results for query: 'Powerful motor and easy to clean blender'\n",
      "\n",
      "Score: 0.6316\n",
      "Review Text: Very good machine This purchase was great for me, very efficient and clean. One of my best investments.\n",
      "Review Time (unix): 1142121600\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6192\n",
      "Review Text: Beautiful & Efficient..LOVE IT!!!! Bought this in October and love it!!!!! Does not look cheap and motor is powerful and quiet.  Best buy I  have made.\n",
      "Review Time (unix): 1385251200\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6015\n",
      "Review Text: couldn't be better Was in dire need of this motor.  It came fast, and fit perfectly.  Needed an electric adapter, but it was sent fast, and with no additional charge.  My dishwasher runs like new ... and it's fifteen years old!\n",
      "Review Time (unix): 1357257600\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.5998\n",
      "Review Text: Satisfied Customer Very happy with my Waste King garbage disposal purchase.  The 1/2 HP motor is very powerful, quiet, and efficient.  Works great!\n",
      "Review Time (unix): 1379462400\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.5961\n",
      "Review Text: Impressive power and quietness. Excellent disposer. My plumber reccomended a 3/4 horsepower motor or greater. After he installed it, even he was impressed with its smoothness and how quietit is. Only caveat is that since it is so quiet and vibration free, you have to be careful not to put your hands down it while it is running! Highly reccomended.\n",
      "Review Time (unix): 1386633600\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Requirement 5 - Execute the queries from Requirement 4 and capture the outputs\n",
    "# This code iterates through all Group C queries, performs similarity search in Milvus,\n",
    "# and prints the top results for each query for verification and reporting.\n",
    "\n",
    "from pymilvus import Collection\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load Milvus collection and embedding model\n",
    "collection = Collection(\"appliance_reviews\")\n",
    "collection.load()\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Your list of Group C queries (replace or extend with all queries you want to run)\n",
    "group_c_queries = [\n",
    "    \"It could so nearly have been a great fridge, but it's the design that brings it down.\",\n",
    "    \"This microwave started to make a lot of noise after only a few days\",\n",
    "    \"Powerful motor and easy to clean blender\",\n",
    "    # Add your other queries here...\n",
    "]\n",
    "\n",
    "# Execute each query and print results\n",
    "for query_text in group_c_queries:\n",
    "    print(f\"Search results for query: '{query_text}'\\n\")\n",
    "    \n",
    "    # Encode the query\n",
    "    query_embedding = model.encode([query_text]).tolist()\n",
    "    \n",
    "    # Perform similarity search, top 5 results\n",
    "    results = collection.search(\n",
    "        data=query_embedding,\n",
    "        anns_field=\"embedding\",\n",
    "        param={\"metric_type\": \"IP\", \"params\": {\"nprobe\": 10}},\n",
    "        limit=5,\n",
    "        output_fields=[\"combined_text\", \"unixReviewTime\"]\n",
    "    )\n",
    "    \n",
    "    # Display search results\n",
    "    for hit in results[0]:\n",
    "        print(f\"Score: {hit.score:.4f}\")\n",
    "        print(f\"Review Text: {hit.entity.get('combined_text')}\")\n",
    "        print(f\"Review Time (unix): {hit.entity.get('unixReviewTime')}\")\n",
    "        print(\"-\" * 80)\n",
    "    print(\"\\n\" + \"=\"*100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24171a24-e843-442f-8651-e32a7ef6afe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
